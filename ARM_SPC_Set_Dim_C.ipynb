{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "Startdate=datetime.datetime.now().date()-datetime.timedelta(30)\n",
    "finishDate=datetime.datetime.now().date()-datetime.timedelta(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_17856\\594276586.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  max_date_df = pd.read_sql(max_date_query, cnxn)\n",
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_17856\\594276586.py:112: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  datasets = pd.read_sql(query, cnxn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date + 1 day: 2023-08-29\n",
      "           Date  %Yield  Cycle_time (sec)  Down time (min)    AVG     STD  \\\n",
      "0    2023-08-08  100.00              0.93              0.0  1.346  0.0092   \n",
      "1    2023-08-09   98.73              1.05              0.0  1.656  0.0082   \n",
      "2    2023-08-09   99.47              0.56              0.0  1.357  0.0108   \n",
      "3    2023-08-09  100.00              1.49           1374.0  3.189  0.0081   \n",
      "4    2023-08-09  100.00              0.88              0.0  1.763  0.0067   \n",
      "..          ...     ...               ...              ...    ...     ...   \n",
      "128  2023-08-17   99.68              0.44              0.0  4.450  0.0086   \n",
      "129  2023-08-17  100.00              0.60              0.0  3.178  0.0087   \n",
      "130  2023-08-19   99.68              0.62              0.0  2.331  0.0101   \n",
      "131  2023-08-25  100.00              0.61              0.0  1.755  0.0096   \n",
      "132  2023-08-25  100.00              1.23              0.0  3.184  0.0071   \n",
      "\n",
      "      CPK   Model     Machine  Line  Parameter  \n",
      "0    1.31  ROSE2D  FB-028-085   1-8  Set_Dim_C  \n",
      "1    0.73  CIMBP4  FB-028-043  3-24  Set_Dim_C  \n",
      "2    0.77  ROSE2D  FB-028-032   1-8  Set_Dim_C  \n",
      "3    1.21  V15C2D  FB-028-038   1-6  Set_Dim_C  \n",
      "4    1.88  V15C4D  FB-028-041  3-22  Set_Dim_C  \n",
      "..    ...     ...         ...   ...        ...  \n",
      "128  1.39  V15C1D  FB-028-011   2-9  Set_Dim_C  \n",
      "129  1.41  V15C2D  FB-028-006  3-29  Set_Dim_C  \n",
      "130  1.07  ROSE1L  FB-028-047   1-9  Set_Dim_C  \n",
      "131  1.07  V11 4D  FB-028-041  3-22  Set_Dim_C  \n",
      "132  1.61  V15C2D  FB-028-037   1-6  Set_Dim_C  \n",
      "\n",
      "[133 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "# Some other example server values are\n",
    "# server = 'localhost\\sqlexpress' # for a named instance\n",
    "# server = 'myserver,port' # to specify an alternate port\n",
    "server = '192.168.101.219' \n",
    "database = 'DataforAnalysis' \n",
    "username = 'DATALYZER' \n",
    "password = 'NMB54321'  \n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "# select 26 rows from SQL table to insert in dataframe.\n",
    "# Query to get the maximum date\n",
    "max_date_query = \"\"\"\n",
    "    SELECT DATEADD(day, 1, MAX([Date])) as MaxDate\n",
    "    FROM [DataforAnalysis].[dbo].[Store_SPC];\n",
    "\"\"\"\n",
    "max_date_df = pd.read_sql(max_date_query, cnxn)\n",
    "\n",
    "# Printing the maximum date with one day added\n",
    "max_date_plus_1 = max_date_df['MaxDate'][0]\n",
    "print(f\"Maximum Date + 1 day: {max_date_plus_1}\")\n",
    "\n",
    "query = f\"\"\"\n",
    "        DECLARE @DynamicSQL AS NVARCHAR(max),\n",
    " @Start NVARCHAR(30) = '{Startdate}',\n",
    " @End NVARCHAR(30) = '{finishDate}',\n",
    " @Parameter NVARCHAR(30) = 'Set_Dim_C';\n",
    "\n",
    "-- CTE แรก\n",
    "WITH BarcodeThan100 AS (\n",
    "    SELECT [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] AS [Date],\n",
    "           COUNT([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Barcode]) AS [countBarcode]\n",
    "    FROM [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester]\n",
    "    INNER JOIN [TransportData].[dbo].[Master_matchings]\n",
    "        ON [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Model = [TransportData].[dbo].[Master_matchings].Model\n",
    "    WHERE [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] BETWEEN @Start AND @End\n",
    "\n",
    "        AND [TransportData].[dbo].[Master_matchings].[createdAt] = (\n",
    "            SELECT MAX([TransportData].[dbo].[Master_matchings].[createdAt])\n",
    "            FROM [TransportData].[dbo].[Master_matchings]\n",
    "        )\n",
    "    GROUP BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date]\n",
    "),\n",
    "XT AS (\n",
    "    SELECT [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] AS [Date],\n",
    "           CASE WHEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME)) < 120\n",
    "                THEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME))\n",
    "                WHEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME)) >= 120\n",
    "                THEN 0\n",
    "           END AS [C/T in sec],\n",
    "           CASE WHEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME)) >= 120\n",
    "                THEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME))\n",
    "                WHEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME)) < 120\n",
    "                THEN 0\n",
    "           END AS [D/T],\n",
    "           [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Set_Dim_C AS [Parameter],\n",
    "           [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Model] AS [model],\n",
    "           [TransportData].[dbo].[Master_matchings].LSL AS [LSL],\n",
    "           [TransportData].[dbo].[Master_matchings].CL AS [CL],\n",
    "           [TransportData].[dbo].[Master_matchings].USL AS [USL],\n",
    "           [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Machine_no] AS [MC],\n",
    "           [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Barcode],\n",
    "           [Line]\n",
    "    FROM BarcodeThan100\n",
    "    LEFT JOIN [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester]\n",
    "        ON BarcodeThan100.Date = [Dynamic_Parallelism_Tester].Date\n",
    "    INNER JOIN [TransportData].[dbo].[Master_matchings]\n",
    "        ON [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Model = [TransportData].[dbo].[Master_matchings].Model\n",
    "    WHERE [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] BETWEEN @Start AND @End\n",
    "        AND [TransportData].[dbo].[Master_matchings].[Parameter] = @Parameter\n",
    "        AND [TransportData].[dbo].[Master_matchings].[createdAt] = (\n",
    "            SELECT MAX([TransportData].[dbo].[Master_matchings].[createdAt])\n",
    "            FROM [TransportData].[dbo].[Master_matchings]\n",
    "        )\n",
    "        AND countBarcode > 100\n",
    "        AND Operator = 'Operator'\n",
    ")\n",
    ", XO AS (\n",
    "    SELECT [Date] AS [Date],\n",
    "           CAST(CONVERT(FLOAT, COUNT(CASE WHEN [Parameter] >= [LSL] AND [Parameter] <= [USL] THEN 1 ELSE NULL END)) /\n",
    "                CONVERT(FLOAT, COUNT(CASE WHEN [Parameter] >= [LSL] AND [Parameter] <= [USL] THEN 1 ELSE NULL END) +\n",
    "                COUNT(CASE WHEN [Parameter] < [LSL] OR [Parameter] > [USL] THEN 1 ELSE NULL END)) * 100 AS DECIMAL(10, 2)) AS [%Yield],\n",
    "           CAST(CONVERT(FLOAT, SUM([C/T in sec])) / COUNT([C/T in sec]) AS DECIMAL(10, 2)) AS [Cycle_time (sec)],\n",
    "           CAST(CONVERT(FLOAT, SUM([D/T])) / 60 AS DECIMAL(10, 0)) AS [Down time (min)],\n",
    "           CAST(AVG([Parameter]) AS DECIMAL(10, 3)) AS [AVG],\n",
    "           CAST(STDEV([Parameter]) AS DECIMAL(10, 4)) AS [STD],\n",
    "           CASE WHEN (CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2)) <\n",
    "                     CAST(CONVERT(FLOAT, ((AVG([Parameter]) - [LSL]) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))) OR\n",
    "                    ((CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2)) >\n",
    "                    CAST(CONVERT(FLOAT, ((AVG([Parameter]) - [LSL]) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))) AND [LSL] = 0)\n",
    "                THEN CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))\n",
    "            WHEN CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2)) >\n",
    "                 CAST(CONVERT(FLOAT, ((AVG([Parameter]) - [LSL]) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))\n",
    "                THEN CAST(CONVERT(FLOAT, ((AVG([Parameter]) - [LSL]) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))\n",
    "            WHEN CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2)) =\n",
    "                 CAST(CONVERT(FLOAT, ((AVG([Parameter]) - [LSL]) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))\n",
    "                THEN CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))\n",
    "           END AS [CPK],\n",
    "           [model] AS [Model],\n",
    "           [MC] AS [Machine],\n",
    "           [Line] AS Line\n",
    "    FROM XT\n",
    "    GROUP BY [Date], [model], [LSL], [CL], [USL], [MC], [Line]\n",
    "\tHAVING  STDEV([Parameter]) != 0 and STDEV([Parameter]) is not null\n",
    "\n",
    ")\n",
    "-- คำสั่ง SQL ส่วนอื่น ๆ\n",
    "SELECT [Date], [%Yield], [Cycle_time (sec)], [Down time (min)], [AVG], [STD], [CPK], [Model], [Machine], [Line],@Parameter as Parameter\n",
    "FROM XO;\n",
    "        \"\"\"\n",
    "datasets = pd.read_sql(query, cnxn)\n",
    "print(datasets.head(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_17856\\3032691257.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  datasets = pd.read_sql(query, cnxn)\n"
     ]
    }
   ],
   "source": [
    "# Your existing code here...\n",
    "\n",
    "# Execute the SQL query and store the results in the 'datasets' DataFrame\n",
    "datasets = pd.read_sql(query, cnxn)\n",
    "\n",
    "# Your existing code here...\n",
    "\n",
    "# Establish a new connection for inserting the data into the target table\n",
    "insert_server = '192.168.101.219'\n",
    "insert_database = 'DataforAnalysis'\n",
    "insert_username = 'DATALYZER'\n",
    "insert_password = 'NMB54321'\n",
    "insert_cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+insert_server+';DATABASE='+insert_database+';UID='+insert_username+';PWD='+ insert_password)\n",
    "insert_cursor = insert_cnxn.cursor()\n",
    "\n",
    "# Iterate through the rows of the 'datasets' DataFrame and insert data into the target table\n",
    "for index, row in datasets.iterrows():\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO [DataforAnalysis].[dbo].[Store_SPC] ([Date], [Model], [Line], [Machine], [%Yield], [Cycle_time (sec)],\n",
    "        [Down time (min)], [AVG], [STD], [CPK], [Parameter])\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "    values = (row['Date'], row['Model'], row['Line'], row['Machine'], row['%Yield'], row['Cycle_time (sec)'],\n",
    "              row['Down time (min)'], row['AVG'], row['STD'], row['CPK'], row['Parameter'])\n",
    "    insert_cursor.execute(insert_query, values)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "insert_cursor.commit()\n",
    "insert_cursor.close()\n",
    "insert_cnxn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_17856\\782290832.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  max_date_df = pd.read_sql(max_date_query, cnxn)\n",
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_17856\\782290832.py:112: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dataSTD = pd.read_sql(query, cnxn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date + 1 day: 2023-08-29\n",
      "          Date   Model  Line  Machine  %Yield  Cycle_time (sec)  \\\n",
      "0   2023-08-09  V15C4D  3-22  Average  100.00              0.97   \n",
      "1   2023-08-11  M11P5D  2-14  Average   99.60              0.57   \n",
      "2   2023-08-17  LONGSP   3-6  Average   98.09              0.49   \n",
      "3   2023-08-25  V11 4D  3-22  Average   99.17              1.00   \n",
      "4   2023-08-25  V15C1D   2-9  Average  100.00              3.00   \n",
      "..         ...     ...   ...      ...     ...               ...   \n",
      "78  2023-08-25  EVANBP  2-10  Average  100.00              1.77   \n",
      "79  2023-08-25  ROSE1L   1-9  Average  100.00              1.08   \n",
      "80  2023-08-25  ROSE2D   1-8  Average  100.00              1.36   \n",
      "81  2023-08-25  V15C2D   1-6  Average  100.00              1.00   \n",
      "82  2023-08-27  CIMBP4  3-24  Average  100.00              0.00   \n",
      "\n",
      "    Down time (min)    AVG     STD   CPK     USL      CL     LSL  Parameter  \n",
      "0               0.0  1.762  0.0070  1.76  1.8009  1.7628  1.7247  Set_Dim_C  \n",
      "1               0.0 -0.212  0.0081  0.96 -0.1890 -0.2140 -0.2390  Set_Dim_C  \n",
      "2               0.0  0.512  0.0139  0.83  0.5537  0.5156  0.4775  Set_Dim_C  \n",
      "3               0.0  1.758  0.0098  1.14  1.8009  1.7628  1.7247  Set_Dim_C  \n",
      "4            1279.0  4.455  0.0063  1.65  4.4860  4.4480  4.4100  Set_Dim_C  \n",
      "..              ...    ...     ...   ...     ...     ...     ...        ...  \n",
      "78              0.0  0.837  0.0094  1.11  0.8687  0.8306  0.7925  Set_Dim_C  \n",
      "79              0.0  2.322  0.0084  1.54  2.3630  2.3230  2.2830  Set_Dim_C  \n",
      "80              0.0  1.348  0.0083  1.35  1.3820  1.3420  1.3020  Set_Dim_C  \n",
      "81              0.0  3.184  0.0071  1.61  3.2181  3.1800  3.1419  Set_Dim_C  \n",
      "82            252.0  1.651  0.0042  1.85  1.6741  1.6360  1.5979  Set_Dim_C  \n",
      "\n",
      "[83 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "# Some other example server values are\n",
    "# server = 'localhost\\sqlexpress' # for a named instance\n",
    "# server = 'myserver,port' # to specify an alternate port\n",
    "server = '192.168.101.219' \n",
    "database = 'DataforAnalysis' \n",
    "username = 'DATALYZER' \n",
    "password = 'NMB54321'  \n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "# select 26 rows from SQL table to insert in dataframe.\n",
    "# Query to get the maximum date\n",
    "max_date_query = \"\"\"\n",
    "    SELECT DATEADD(day, 1, MAX([Date])) as MaxDate\n",
    "    FROM [DataforAnalysis].[dbo].[SPC_STD_MC];\n",
    "\"\"\"\n",
    "max_date_df = pd.read_sql(max_date_query, cnxn)\n",
    "\n",
    "# Printing the maximum date with one day added\n",
    "max_date_plus_1 = max_date_df['MaxDate'][0]\n",
    "print(f\"Maximum Date + 1 day: {max_date_plus_1}\")\n",
    "\n",
    "query = f\"\"\"\n",
    "  DECLARE @DynamicSQL AS NVARCHAR(max),\n",
    " @Start NVARCHAR(30) = '{Startdate}',\n",
    " @End NVARCHAR(30) = '{finishDate}',\n",
    " @Parameter NVARCHAR(30) = 'Set_Dim_C';\n",
    "\n",
    "    WITH BarcodeThan100 as(\n",
    "      select [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] as [Date]\n",
    "             ,count([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Barcode]) as  [countBarcode]\n",
    "             from [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester]\n",
    "                INNER JOIN [TransportData].[dbo].[Master_matchings]\n",
    "                ON [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Model = [TransportData].[dbo].[Master_matchings].Model\n",
    "             where [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] BETWEEN  @Start AND  @End\n",
    "             and [TransportData].[dbo].[Master_matchings].[createdAt] = (select max([TransportData].[dbo].[Master_matchings].[createdAt]) from [TransportData].[dbo].[Master_matchings])\n",
    "       group by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date]\n",
    "       )\n",
    "    ,XT (x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11) as\n",
    "        (select [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] as [Date]\n",
    "        ,case when datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time)) < 120\n",
    "        then datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time))\n",
    "        when datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time)) >= 120 then 0 end as [C/T in sec]\n",
    "        ,case when datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time)) >= 120\n",
    "        then datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time))\n",
    "        when datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time)) < 120 then 0 end as [D/T]\n",
    "        ,[DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Set_Dim_C as [Parameter]\n",
    "        ,[DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Model] as [model]\n",
    "        ,[TransportData].[dbo].[Master_matchings].LSL as [LSL]\n",
    "        ,[TransportData].[dbo].[Master_matchings].CL as [CL]\n",
    "        ,[TransportData].[dbo].[Master_matchings].USL as [USL]\n",
    "        ,'Average' as [AVG]\n",
    "        ,[DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Barcode]\n",
    "\t\t,Line\n",
    "        from BarcodeThan100\n",
    "                                left join [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester]\n",
    "                                on BarcodeThan100.Date = [Dynamic_Parallelism_Tester].Date\n",
    "        INNER JOIN [TransportData].[dbo].[Master_matchings]\n",
    "        ON [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Model = [TransportData].[dbo].[Master_matchings].Model\n",
    "         where [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] BETWEEN  @Start AND  @End\n",
    "        and [TransportData].[dbo].[Master_matchings].[Parameter] = @Parameter\n",
    "        and [TransportData].[dbo].[Master_matchings].[createdAt] = (select max([TransportData].[dbo].[Master_matchings].[createdAt]) from [TransportData].[dbo].[Master_matchings])\n",
    "        and countBarcode >100\n",
    "        and Operator = 'Operator'\n",
    "        ),\n",
    "     XO (x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13) as (\n",
    "    select \n",
    "        x1 as [Date],\n",
    "        ISNULL(cast(convert(float,count(case when x4 >= x6 and x4 <= x8 then 1 else null end))/\n",
    "        convert(float,count(case when x4 >= x6 and x4 <= x8 then 1 else null end)\n",
    "        + count(case when x4 < x6 or x4 > x8 then 1 else null end)) * 100 AS DECIMAL(10, 2)), 0) as [%Yield], -- Replace NULL with 0\n",
    "        ISNULL(cast(convert(float,sum(x2))/count(x2) as DECIMAL(10, 2)), 0) as [Cycle_time (sec)], -- Replace NULL with 0\n",
    "        ISNULL(cast(convert(float,sum(x3))/60 as decimal(10,0)), 0) as [Down time (min)], -- Replace NULL with 0\n",
    "        ISNULL(cast(AVG(x4) as decimal(10,3)), 0) as [AVG], -- Replace NULL with 0\n",
    "        ISNULL(cast(stdev(x4) as decimal(10,4)), 0) as [STD], -- Replace NULL with 0\n",
    "        case when (cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2)) < cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2))) or\n",
    "        ((cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2)) > cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2))) and x6 = 0)\n",
    "        then ISNULL(cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2)), 0) when cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2))\n",
    "        > cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2))\n",
    "        then ISNULL(cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2)), 0) when cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2))\n",
    "        = cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2))\n",
    "        then ISNULL(cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2)), 0) end as [CPK],\n",
    "        x5 as [Model],\n",
    "        x6 as [LSL],\n",
    "        x7 as [CL],\n",
    "        x8 as [USL],\n",
    "        x9 as [Machine],\n",
    "        x11 as Line\n",
    "    from XT\n",
    "    group by x1,x5,x6,x7,x8,x9,x11\n",
    "    having STDEV(x4) != 0 and STDEV(x4) is not null\n",
    ")\n",
    "      select \n",
    "      XO.x1 as [Date]\n",
    "\t  ,XO.x8 as [Model]\n",
    "      ,XO.x13 as Line\n",
    "      ,XO.x12 as [Machine]\n",
    "      ,XO.x2 as [%Yield]\n",
    "      ,XO.x3 as [Cycle_time (sec)]\n",
    "      ,XO.x4 as [Down time (min)]\n",
    "      ,XO.x5 as [AVG]\n",
    "      ,XO.x6 as [STD]\n",
    "      ,XO.x7 as [CPK]\n",
    "    \n",
    "      ,x11 as [USL]\n",
    "      ,x10 as [CL]\n",
    "      ,x9 as [LSL]\n",
    "\t  ,@Parameter as Parameter\n",
    "      from XO\n",
    "        \"\"\"\n",
    "dataSTD = pd.read_sql(query, cnxn)\n",
    "print(dataSTD.head(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_17856\\4262995815.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  datasets = pd.read_sql(query, cnxn)\n"
     ]
    }
   ],
   "source": [
    "# Your existing code here...\n",
    "\n",
    "# Execute the SQL query and store the results in the 'datasets' DataFrame\n",
    "datasets = pd.read_sql(query, cnxn)\n",
    "\n",
    "# Your existing code here...\n",
    "\n",
    "# Establish a new connection for inserting the data into the target table\n",
    "insert_server = '192.168.101.219'\n",
    "insert_database = 'DataforAnalysis'\n",
    "insert_username = 'DATALYZER'\n",
    "insert_password = 'NMB54321'\n",
    "insert_cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+insert_server+';DATABASE='+insert_database+';UID='+insert_username+';PWD='+ insert_password)\n",
    "insert_cursor = insert_cnxn.cursor()\n",
    "\n",
    "# Iterate through the rows of the 'datasets' DataFrame and insert data into the target table\n",
    "for index, row in dataSTD.iterrows():\n",
    "    insert_query = f\"\"\"\n",
    "        insert into [DataforAnalysis].[dbo].[SPC_STD_MC] ([Date], [Model], [Line], [Machine], [%Yield], [Cycle_time (sec)],\n",
    "        [Down time (min)], [AVG], [STD], [CPK],[LSL],[CL],[USL],[Parameter])\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? , ? )\n",
    "    \"\"\"\n",
    "    values = (row['Date'], row['Model'], row['Line'], row['Machine'], row['%Yield'], row['Cycle_time (sec)'],\n",
    "              row['Down time (min)'], row['AVG'], row['STD'], row['CPK'],row['LSL'],row['CL'],row['USL'], row['Parameter'])\n",
    "    insert_cursor.execute(insert_query, values)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "insert_cursor.commit()\n",
    "insert_cursor.close()\n",
    "insert_cnxn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
