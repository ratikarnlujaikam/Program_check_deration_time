{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# Date= datetime.datetime.now().date()-datetime.timedelta(1)\n",
    "# Line='3-10'\n",
    "# Model='LONGSP'\n",
    "# Startdate=datetime.datetime.now().date()-datetime.timedelta(1)-datetime.timedelta(150)\n",
    "# finishDate=datetime.datetime.now().date()-datetime.timedelta(1)-datetime.timedelta(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "Date= datetime.datetime.now().date()\n",
    "Line='3-10'\n",
    "Model='LONGSP'\n",
    "Startdate=datetime.datetime.now().date()-datetime.timedelta(150)\n",
    "finishDate=datetime.datetime.now().date()-datetime.timedelta(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyodbc\n",
    "# import pandas as pd\n",
    "# # Some other example server values are\n",
    "# # server = 'localhost\\sqlexpress' # for a named instance\n",
    "# # server = 'myserver,port' # to specify an alternate port\n",
    "# server = '192.168.101.219' \n",
    "# database = 'DataforAnalysis' \n",
    "# username = 'DATALYZER' \n",
    "# password = 'NMB54321'  \n",
    "# cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "# cursor = cnxn.cursor()\n",
    "# # select 26 rows from SQL table to insert in dataframe.\n",
    "# query = \"SELECT [Projection1],[Datum_probe],convert(float,[Max_force]) as [Max_force],[Set_Dim_A],[Set_Dim_B],[Set_Dim_C],[Diecast_Pivot_2] FROM [Diecast].[dbo].[Pivot]  inner join [TransportData].[dbo].[Matching_Auto_Unit1] on [Pivot].Diecast_S_N=[Matching_Auto_Unit1].Barcode_Base  inner join [DataforAnalysis].[dbo].[DataML] as s on s.Barcode_motor=[Matching_Auto_Unit1].Barcode_Motor  WHERE s.[Model] = '\"+Model+\"' AND s.[Line] = '\"+Line+\"' AND s.[Date] BETWEEN '\"+str(Startdate)+\"' and '\"+str(finishDate)+\"' and ([Projection1] is not null and [Datum_probe] is not null and [Max_force] is not null and [Set_Dim_A] is not null and [Set_Dim_B] is not null and [Set_Dim_C] is not null and [Diecast_Pivot_2] is not null)and [Projection1] !='0'and S.[Time]=(SELECT MAX([Time])FROM [DataforAnalysis].[dbo].[DataML]WHERE [Barcode_motor]=S.[Barcode_motor]);\"\n",
    "# datasets = pd.read_sql(query, cnxn)\n",
    "# print(datasets.head(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_16600\\1078993365.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  datasets = pd.read_sql(query, cnxn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Projection1, Datum_probe, Max_force, Set_Dim_A, Set_Dim_B, Set_Dim_C, Diecast_Pivot_2]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "# Some other example server values are\n",
    "# server = 'localhost\\sqlexpress' # for a named instance\n",
    "# server = 'myserver,port' # to specify an alternate port\n",
    "server = '192.168.101.219' \n",
    "database = 'DataforAnalysis' \n",
    "username = 'DATALYZER' \n",
    "password = 'NMB54321'  \n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "# select 26 rows from SQL table to insert in dataframe.\n",
    "query = \"SELECT [Projection1],[Datum_probe],convert(float,[Max_force]) as [Max_force],[Set_Dim_A],[Set_Dim_B],[Set_Dim_C],[Diecast_Pivot_2]FROM [Diecast].[dbo].[Pivot] join [TransportData].[dbo].[Matching_Auto_Unit1] on [Pivot].Diecast_S_N=[Matching_Auto_Unit1].Barcode_Base join [DataforAnalysis].[dbo].[DataML] on [DataML].Barcode_motor=[Matching_Auto_Unit1].Barcode_Motor   WHERE [DataML].[Model] = '\"+Model+\"' AND [DataML].[Line] = '\"+Line+\"' AND [DataML].[Date] BETWEEN '\"+str(Startdate)+\"' and '\"+str(finishDate)+\"'and ([Projection1] is not null and [Datum_probe] is not null and [Max_force] is not null and [Set_Dim_A] is not null and [Set_Dim_B] is not null and [Set_Dim_C] is not null and [Diecast_Pivot_2] is not null)and [Projection1] !='0' and [Projection1]>0 and [Projection1] < 1;\"\n",
    "datasets = pd.read_sql(query, cnxn)\n",
    "print(datasets.head(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Bin        Bin2 Datum_probe_Min Datum_probe_Max Max_force_Min  \\\n",
      "0   A           -4               -infinity          124.99     -infinity   \n",
      "1   B           -3                     125          249.99           300   \n",
      "2   C           -2                     250          374.99        833.33   \n",
      "3   D           -1                     375          499.99       1366.67   \n",
      "4   E           1                      500          624.99          1900   \n",
      "5   F           2                      625          749.99       2433.33   \n",
      "6   G           3                      750             875       2966.67   \n",
      "7   H           4                   875.01       +infinity       3500.01   \n",
      "8   Pass        Pass                                  None          None   \n",
      "9   Fail        Fail                                  None          None   \n",
      "10  Fail        Fail                  None            None          None   \n",
      "\n",
      "   Max_force_Max Set_Dim_A_Min Set_Dim_A_Max Set_Dim_B_Min Set_Dim_B_Max  \\\n",
      "0         299.99     -infinity        0.4774     -infinity        0.4774   \n",
      "1         833.32        0.4775        0.4901        0.4775        0.4901   \n",
      "2        1366.66        0.4902        0.5028        0.4902        0.5028   \n",
      "3        1899.99        0.5029        0.5155        0.5029        0.5155   \n",
      "4        2433.32        0.5156        0.5282        0.5156        0.5282   \n",
      "5        2966.66        0.5283        0.5409        0.5283        0.5409   \n",
      "6           3500         0.541        0.5537         0.541        0.5537   \n",
      "7      +infinity        0.5538     +infinity        0.5538     +infinity   \n",
      "8           None          None          None          None          None   \n",
      "9           None          None          None          None          None   \n",
      "10          None          None          None          None          None   \n",
      "\n",
      "   Set_Dim_C_Min Set_Dim_C_Max Pivot_Height_Min Pivot_Height_Max Pivot_2_Min  \\\n",
      "0      -infinity        0.4774        -infinity           -9.403   -infinity   \n",
      "1         0.4775        0.4901          -9.4031          -9.3945      9.3524   \n",
      "2         0.4902        0.5028          -9.3946           -9.386      9.3607   \n",
      "3         0.5029        0.5155          -9.3861          -9.3776      9.3692   \n",
      "4         0.5156        0.5282          -9.3777          -9.3691      9.3777   \n",
      "5         0.5283        0.5409          -9.3692          -9.3606      9.3861   \n",
      "6          0.541        0.5537          -9.3607          -9.3523      9.3946   \n",
      "7         0.5538     +infinity          -9.3524        +infinity      9.4031   \n",
      "8           None          None             None                         None   \n",
      "9           None          None             None                         None   \n",
      "10          None          None             None                         None   \n",
      "\n",
      "   Pivot_2_Max   KPOV_Min   KPOV_Max  \n",
      "0       9.3523       None       None  \n",
      "1       9.3606       None       None  \n",
      "2       9.3691       None       None  \n",
      "3       9.3776       None       None  \n",
      "4        9.386       None       None  \n",
      "5       9.3945       None       None  \n",
      "6        9.403       None       None  \n",
      "7    +infinity       None       None  \n",
      "8         None     0.4648     0.5664  \n",
      "9         None  -infinity     0.4647  \n",
      "10        None     0.5665  +infinity  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_16600\\445518909.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  spec = pd.read_sql(query, cnxn)\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "# Some other example server values are\n",
    "# server = 'localhost\\sqlexpress' # for a named instance\n",
    "# server = 'myserver,port' # to specify an alternate port\n",
    "server = '192.168.101.219' \n",
    "database = 'DataforAnalysis' \n",
    "username = 'DATALYZER' \n",
    "password = 'NMB54321'  \n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "# select 26 rows from SQL table to insert in dataframe.\n",
    "query = \"SELECT [Bin],[Bin2],[Datum_probe_Min],[Datum_probe_Max],[Max_force_Min],[Max_force_Max],[Set_Dim_A_Min],[Set_Dim_A_Max],[Set_Dim_B_Min],[Set_Dim_B_Max],[Set_Dim_C_Min],[Set_Dim_C_Max],[Pivot_Height_Min],[Pivot_Height_Max],[Pivot_2_Min],[Pivot_2_Max],[KPOV_Min],[KPOV_Max]FROM [DataforAnalysis].[dbo].[Reference];\"\n",
    "spec = pd.read_sql(query, cnxn)\n",
    "print(spec.head(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array length 8 does not match index length 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\ML\\src\\ARM_3-10_up 18-05-23.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m DataFrame\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data1 \u001b[39m=\u001b[39m{\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m:Date,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m'\u001b[39m\u001b[39mbetweenDate\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mstr\u001b[39m(Startdate)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m - \u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(finishDate),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m'\u001b[39m\u001b[39mProjection\u001b[39m\u001b[39m'\u001b[39m:datasets\u001b[39m.\u001b[39mdescribe()[\u001b[39m'\u001b[39m\u001b[39mProjection1\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m }\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m dff1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(data1,columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mDate\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mbetweenDate\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mModel\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mLine\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mdescribe1\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39mstr\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mDatum_probe\u001b[39;49m\u001b[39m'\u001b[39;49m),\u001b[39mstr\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mMax_force\u001b[39;49m\u001b[39m'\u001b[39;49m),\u001b[39mstr\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mSet_Dim_A\u001b[39;49m\u001b[39m'\u001b[39;49m),\u001b[39mstr\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mSet_Dim_B\u001b[39;49m\u001b[39m'\u001b[39;49m),\u001b[39mstr\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mSet_Dim_C\u001b[39;49m\u001b[39m'\u001b[39;49m),\u001b[39mstr\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mDiecast_Pivot_2\u001b[39;49m\u001b[39m'\u001b[39;49m),\u001b[39mstr\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mProjection\u001b[39;49m\u001b[39m'\u001b[39;49m)])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdisplaying the dataframe with data as record\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(dff1)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:663\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    657\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    658\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    659\u001b[0m     )\n\u001b[0;32m    661\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    662\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 663\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    664\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    665\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:448\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    444\u001b[0m missing \u001b[39m=\u001b[39m arrays\u001b[39m.\u001b[39misna()\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    446\u001b[0m     \u001b[39m# GH10856\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     \u001b[39m# raise ValueError if only scalars in dict\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m     index \u001b[39m=\u001b[39m _extract_index(arrays[\u001b[39m~\u001b[39;49mmissing])\n\u001b[0;32m    449\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    450\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:680\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m lengths[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m    676\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    677\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marray length \u001b[39m\u001b[39m{\u001b[39;00mlengths[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m does not match index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    678\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlength \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m         )\n\u001b[1;32m--> 680\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m    681\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    682\u001b[0m     index \u001b[39m=\u001b[39m default_index(lengths[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: array length 8 does not match index length 4"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "data1 ={\n",
    "'Date':Date,\n",
    "'betweenDate':str(Startdate)+' - '+str(finishDate),\n",
    "'Model':Model,\n",
    "'Line':Line,\n",
    "\n",
    "'describe1':['count','mean','std','min','25%','50%','75%','max'\n",
    "],\n",
    "'Datum_probe':datasets.describe()['Datum_probe'],\n",
    "'Max_force':datasets.describe()['Max_force'],\n",
    "'Set_Dim_A':datasets.describe()['Set_Dim_A'],\n",
    "'Set_Dim_B':datasets.describe()['Set_Dim_B'],\n",
    "'Set_Dim_C':datasets.describe()['Set_Dim_C'],\n",
    "'Diecast_Pivot_2':datasets.describe()['Diecast_Pivot_2'],\n",
    "'Projection':datasets.describe()['Projection1'],\n",
    "}\n",
    "dff1 = pd.DataFrame(data1,columns=['Date','betweenDate','Model','Line','describe1',str('Datum_probe'),str('Max_force'),str('Set_Dim_A'),str('Set_Dim_B'),str('Set_Dim_C'),str('Diecast_Pivot_2'),str('Projection')])\n",
    "print(\"displaying the dataframe with data as record\")\n",
    "print(dff1)\n",
    "print(\"-------------------------------Converting into csv file with a new a new file name ------------------------------------\")\n",
    "# dff1.to_csv(\"C:\\\\Users\\\\IT\\\\Desktop\\\\Date ML\\\\LSPdescribe.csv\")\n",
    "# dff1=pd.read_csv(\"C:\\\\Users\\\\IT\\\\Desktop\\\\Date ML\\\\LSPdescribe.csv\")\n",
    "# print(dff1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "# insert data from csv file into dataframe.\n",
    "# working directory for csv file: type \"pwd\" in Azure Data Studio or Linux\n",
    "# working directory in Windows c:\\users\\username\n",
    "# Some other example server values are\n",
    "# server = 'localhost\\sqlexpress' # for a named instance\n",
    "# server = 'myserver,port' # to specify an alternate port\n",
    "server = '192.168.101.219' \n",
    "database = 'DataforAnalysis' \n",
    "username = 'DATALYZER' \n",
    "password = 'NMB54321'  \n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "# Insert Dataframe into SQL Server:\n",
    "for index, row in dff1.iterrows():\n",
    "     cursor.execute(\"INSERT INTO [DataforAnalysis].[dbo].[DescribeML](Date,betweenDate,Model,Line,describe1,Datum_probe,Max_force,Set_Dim_A,Set_Dim_B,Set_Dim_C,Diecast_Pivot_2,Projection) values ('\"+str(row.Date)+\"','\"+row.betweenDate+\"','\"+row.Model+\"','\"+row.Line+\"','\"+str(row.describe1)+\"','\"+str(row.Datum_probe)+\"','\"+str(row.Max_force)+\"','\"+str(row.Set_Dim_A)+\"','\"+str(row.Set_Dim_B)+\"','\"+str(row.Set_Dim_C)+\"','\"+str(row.Diecast_Pivot_2)+\"','\"+str(row.Projection)+\"')\")\n",
    "\n",
    "cnxn.commit()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['Projection1']=pd.cut(datasets['Projection1'],bins=[-np.inf,0.4647,0.5664,np.inf],labels=['fail_low','pass','fail_high'])\n",
    "datasets['Projection1'].replace('fail_low','fail',inplace=True)\n",
    "datasets['Projection1'].replace('fail_high','fail',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'pass': 278016, 'fail': 2082})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(datasets['Projection1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# over_sampling คือการทำค่า fail 1284 ให้เท่ากับค่า pass 271k เพื่อให้ data ในการ train เพิ่มมากขึ้น\n",
    "from collections import Counter\n",
    "\n",
    "k = 3\n",
    "X = datasets.loc[:, datasets.columns != 'Projection1']\n",
    "y = datasets.Projection1\n",
    "\n",
    "# sampling_strategy=0.1 oversampling 10%\n",
    "sm = SMOTE(sampling_strategy='minority', k_neighbors=k, random_state=100)\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "\n",
    "datasets = pd.concat([pd.DataFrame(X_res), pd.DataFrame(y_res)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'pass': 278016, 'fail': 278016})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(datasets['Projection1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datum_3LCL = spec['Datum_probe_Max'][0]\n",
    "Datum_2LCL = spec['Datum_probe_Max'][1]\n",
    "Datum_LCL = spec['Datum_probe_Max'][2]\n",
    "Datum_CL = spec['Datum_probe_Max'][3]\n",
    "Datum_UCL = spec['Datum_probe_Max'][4]\n",
    "Datum_2UCL = spec['Datum_probe_Max'][5]\n",
    "Datum_3UCL = spec['Datum_probe_Max'][6]\n",
    "\n",
    "Max_3LCL = spec['Max_force_Max'][0]\n",
    "Max_2LCL = spec['Max_force_Max'][1]\n",
    "Max_LCL = spec['Max_force_Max'][2]\n",
    "Max_CL = spec['Max_force_Max'][3]\n",
    "Max_UCL = spec['Max_force_Max'][4]\n",
    "Max_2UCL = spec['Max_force_Max'][5]\n",
    "Max_3UCL = spec['Max_force_Max'][6]\n",
    "\n",
    "Set_Dim_A_3LCL = spec['Set_Dim_A_Max'][0]\n",
    "Set_Dim_A_2LCL = spec['Set_Dim_A_Max'][1]\n",
    "Set_Dim_A_LCL = spec['Set_Dim_A_Max'][2]\n",
    "Set_Dim_A_CL = spec['Set_Dim_A_Max'][3]\n",
    "Set_Dim_A_UCL = spec['Set_Dim_A_Max'][4]\n",
    "Set_Dim_A_2UCL = spec['Set_Dim_A_Max'][5]\n",
    "Set_Dim_A_3UCL = spec['Set_Dim_A_Max'][6]\n",
    "\n",
    "\n",
    "Set_Dim_B_3LCL = spec['Set_Dim_B_Max'][0]\n",
    "Set_Dim_B_2LCL = spec['Set_Dim_B_Max'][1]\n",
    "Set_Dim_B_LCL = spec['Set_Dim_B_Max'][2]\n",
    "Set_Dim_B_CL = spec['Set_Dim_B_Max'][3]\n",
    "Set_Dim_B_UCL = spec['Set_Dim_B_Max'][4]\n",
    "Set_Dim_B_2UCL = spec['Set_Dim_B_Max'][5]\n",
    "Set_Dim_B_3UCL = spec['Set_Dim_B_Max'][6]\n",
    "\n",
    "Set_Dim_C_3LCL = spec['Set_Dim_C_Max'][0]\n",
    "Set_Dim_C_2LCL = spec['Set_Dim_C_Max'][1]\n",
    "Set_Dim_C_LCL = spec['Set_Dim_C_Max'][2]\n",
    "Set_Dim_C_CL = spec['Set_Dim_C_Max'][3]\n",
    "Set_Dim_C_UCL = spec['Set_Dim_C_Max'][4]\n",
    "Set_Dim_C_2UCL = spec['Set_Dim_C_Max'][5]\n",
    "Set_Dim_C_3UCL = spec['Set_Dim_C_Max'][6]\n",
    "\n",
    "\n",
    "Diecast_Pivot_2_3LCL = spec['Pivot_2_Max'][0]\n",
    "Diecast_Pivot_2_2LCL = spec['Pivot_2_Max'][1]\n",
    "Diecast_Pivot_2_LCL = spec['Pivot_2_Max'][2]\n",
    "Diecast_Pivot_2_CL = spec['Pivot_2_Max'][3]\n",
    "Diecast_Pivot_2_UCL = spec['Pivot_2_Max'][4]\n",
    "Diecast_Pivot_2_2UCL = spec['Pivot_2_Max'][5]\n",
    "Diecast_Pivot_2_3UCL = spec['Pivot_2_Max'][6]\n",
    "\n",
    "\n",
    "datasets['Datum_probe']=pd.cut(datasets['Datum_probe'],bins=[-np.inf, float(Datum_3LCL), float(Datum_2LCL), float(Datum_LCL), float(Datum_CL), float(Datum_UCL), float(Datum_2UCL), float(Datum_3UCL), np.inf],labels=[-4,-3,-2,-1,1,2,3,4])\n",
    "\n",
    "datasets['Max_force']=pd.cut(datasets['Max_force'],bins=[-np.inf, float(Max_3LCL), float(Max_2LCL), float(Max_LCL), float(Max_CL),float(Max_UCL),float(Max_2UCL),float(Max_3UCL), np.inf],labels=[-4,-3,-2,-1,1,2,3,4])\n",
    "\n",
    "datasets['Set_Dim_A']=pd.cut(datasets['Set_Dim_A'],bins=[-np.inf, float(Set_Dim_A_3LCL), float(Set_Dim_A_2LCL), float(Set_Dim_A_LCL),float(Set_Dim_A_CL),float(Set_Dim_A_UCL),float(Set_Dim_A_2UCL),float(Set_Dim_A_3UCL),np.inf],labels=[-4,-3,-2,-1,1,2,3,4])\n",
    "\n",
    "datasets['Set_Dim_B']=pd.cut(datasets['Set_Dim_B'],bins=[-np.inf, float(Set_Dim_B_3LCL), float(Set_Dim_B_2LCL), float(Set_Dim_B_LCL), float(Set_Dim_B_CL), Set_Dim_B_UCL, Set_Dim_B_2UCL, Set_Dim_B_3UCL, np.inf],labels=[-4,-3,-2,-1,1,2,3,4])\n",
    "\n",
    "datasets['Set_Dim_C']=pd.cut(datasets['Set_Dim_C'],bins=[-np.inf, float(Set_Dim_C_3LCL), float(Set_Dim_C_2LCL), float(Set_Dim_C_LCL), float(Set_Dim_C_CL), float(Set_Dim_C_UCL),float(Set_Dim_C_2UCL),float(Set_Dim_C_3UCL), np.inf],labels=[-4,-3,-2,-1,1,2,3,4])\n",
    "\n",
    "datasets['Diecast_Pivot_2']=pd.cut(datasets['Diecast_Pivot_2'],bins=[-np.inf, float(Diecast_Pivot_2_3LCL), float(Diecast_Pivot_2_2LCL),float(Diecast_Pivot_2_LCL),float(Diecast_Pivot_2_CL),float(Diecast_Pivot_2_UCL),float(Diecast_Pivot_2_2UCL),float(Diecast_Pivot_2_3UCL),np.inf],labels=[-4,-3,-2,-1,1,2,3,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum_probe</th>\n",
       "      <th>Max_force</th>\n",
       "      <th>Set_Dim_A</th>\n",
       "      <th>Set_Dim_B</th>\n",
       "      <th>Set_Dim_C</th>\n",
       "      <th>Diecast_Pivot_2</th>\n",
       "      <th>Projection1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556027</th>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556028</th>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556029</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556030</th>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556031</th>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>fail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>556032 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Datum_probe Max_force Set_Dim_A Set_Dim_B Set_Dim_C Diecast_Pivot_2  \\\n",
       "0               -1        -3        -1        -1        -1               1   \n",
       "1               -1        -3        -1         1         1              -1   \n",
       "2               -1        -2         1         1         2               1   \n",
       "3               -1        -3        -1         1         1               1   \n",
       "4               -1        -3        -1        -2        -1               1   \n",
       "...            ...       ...       ...       ...       ...             ...   \n",
       "556027          -1        -2         1        -1         2               1   \n",
       "556028          -1        -2         1        -1         2              -1   \n",
       "556029          -1        -1        -1        -2        -3               1   \n",
       "556030          -1        -2         1        -1         3               1   \n",
       "556031          -1        -2        -2        -2        -2               1   \n",
       "\n",
       "       Projection1  \n",
       "0             pass  \n",
       "1             pass  \n",
       "2             pass  \n",
       "3             pass  \n",
       "4             pass  \n",
       "...            ...  \n",
       "556027        fail  \n",
       "556028        fail  \n",
       "556029        fail  \n",
       "556030        fail  \n",
       "556031        fail  \n",
       "\n",
       "[556032 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fail       0.88      0.92      0.90     27895\n",
      "        pass       0.92      0.87      0.90     27709\n",
      "\n",
      "    accuracy                           0.90     55604\n",
      "   macro avg       0.90      0.90      0.90     55604\n",
      "weighted avg       0.90      0.90      0.90     55604\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyarc import CBA, TransactionDB\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train, test = train_test_split(datasets, test_size=0.1)\n",
    "\n",
    "txns_train = TransactionDB.from_DataFrame(train)\n",
    "txns_test = TransactionDB.from_DataFrame(test)\n",
    "\n",
    "cba = CBA (support = 0.08, confidence = 0.7, algorithm ='m1')\n",
    "cba.fit(txns_train)\n",
    "\n",
    "y_pred = cba.predict(txns_test)\n",
    "y_test = test['Projection1']\n",
    "print ((classification_report(y_test,y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasp =(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "displaying the dataframe with data as record\n",
      "         Date  Line   Model       Details Procision recall f1_score   support\n",
      "0  2023-06-20  3-10  LONGSP          fail      0.88   0.92     0.90     27895\n",
      "1  2023-06-20  3-10  LONGSP          pass      0.92   0.87     0.90     27709\n",
      "2  2023-06-20  3-10  LONGSP      accuracy                      0.90     55604\n",
      "3  2023-06-20  3-10  LONGSP     macro avg      0.92   0.90     0.90     55604\n",
      "4  2023-06-20  3-10  LONGSP  weighted avg      0.90   0.90     0.90     55604\n",
      "-------------------------------Converting into csv file with a new a new file name ------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "data1 ={\n",
    "'Date':str(Date),\n",
    "'Line':Line,\n",
    "'Model':Model,\n",
    "'Details':[(datasp[63:67]),(datasp[117:121]),(datasp[168:176]),(datasp[221:230]),(datasp[272:284])\n",
    "],\n",
    "'Procision':[datasp[74:78],datasp[128:132],(''),datasp[128:132],datasp[237:241]\n",
    "],\n",
    "'recall':[datasp[84:88],datasp[138:142],(''),datasp[247:251],datasp[301:305]\n",
    "],\n",
    "'f1_score':[datasp[94:98],datasp[148:152],(datasp[203:207]),datasp[257:261],datasp[311:315]\n",
    "],\n",
    "\n",
    "'support':[datasp[103:108],datasp[157:162],datasp[209:217],datasp[265:271],datasp[319:325]\n",
    "],\n",
    "}\n",
    "dff = pd.DataFrame(data1,columns=['Date','Line','Model','Details','Procision','recall','f1_score','support'])\n",
    "print(\"displaying the dataframe with data as record\")\n",
    "print(dff)\n",
    "print(\"-------------------------------Converting into csv file with a new a new file name ------------------------------------\")\n",
    "# df.to_csv(\"C:\\\\Users\\\\IT\\\\Desktop\\\\Date ML\\\\Accuracy ML\\\\LSP3-14 Accuracy.csv\")\n",
    "# df=pd.read_csv(\"C:\\\\Users\\\\IT\\\\Desktop\\\\Date ML\\\\Accuracy ML\\\\LSP3-14 Accuracy.csv\")\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "# Insert Dataframe into SQL Server:\n",
    "for index, row in dff.iterrows():\n",
    "\n",
    "     cursor.execute(\"INSERT INTO [DataforAnalysis].[dbo].[accuracyDataML_Test] (Date,Line,Model,Details,Procision,recall,f1_score,support) values ('\"+row.Date+\"','\"+row.Line+\"','\"+row.Model+\"','\"+row.Details+\"','\"+row.Procision+\"','\"+row.recall+\"','\"+row.f1_score+\"','\"+row.support+\"')\")\n",
    "     # ,(row.Date,row.betweenDate,row.Model,)Procision\n",
    "                    # ('\"+row.Date+\"','\"+row.betweenDate+\"','\"+row.Model+\"','\"+row.Line+\"','\"+row.Datum_probe+\"','\"+ a +\"','\"+row.Set_Dim_A+\"','\"+row.Set_Dim_B+\"','\"+row.Set_Dim_C+\"','\"+row.Diecast_Pivot_2+\"','\"+row.Projection+\"','\"+row.Support+\"','\"+row.Confidence+\"')\")\n",
    "cnxn.commit()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cba1 =cba.clf.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', ' Set_Dim_B=1,Set_Dim_A=1,Datum_probe=-1,Set_Dim_C=1 => pass sup: 0.09 conf: 0.98 len: 5, id: 19', ' Set_Dim_B=1,Set_Dim_A=1,Set_Dim_C=1 => pass sup: 0.09 conf: 0.98 len: 4, id: 20', ' Set_Dim_B=1,Datum_probe=-1,Set_Dim_C=1 => pass sup: 0.14 conf: 0.98 len: 4, id: 23', ' Set_Dim_B=1,Set_Dim_C=1 => pass sup: 0.14 conf: 0.98 len: 3, id: 24', ' Set_Dim_C=1,Datum_probe=-1,Max_force=-3 => pass sup: 0.11 conf: 0.97 len: 4, id: 5', ' Diecast_Pivot_2=-1,Datum_probe=-1,Set_Dim_C=1 => pass sup: 0.11 conf: 0.97 len: 4, id: 17', ' Set_Dim_A=1,Datum_probe=-1,Set_Dim_C=1 => pass sup: 0.17 conf: 0.97 len: 4, id: 35', ' Set_Dim_A=1,Set_Dim_C=1 => pass sup: 0.17 conf: 0.97 len: 3, id: 36', ' Set_Dim_C=1,Max_force=-3 => pass sup: 0.11 conf: 0.97 len: 3, id: 6', ' Datum_probe=-1,Set_Dim_C=1 => pass sup: 0.30 conf: 0.95 len: 3, id: 39', ' Set_Dim_C=2,Max_force=-2,Set_Dim_B=-1 => fail sup: 0.12 conf: 0.95 len: 4, id: 43', ' Diecast_Pivot_2=-1,Set_Dim_C=1 => pass sup: 0.11 conf: 0.95 len: 3, id: 18', ' Diecast_Pivot_2=1,Set_Dim_B=-1,Set_Dim_C=2 => fail sup: 0.12 conf: 0.95 len: 4, id: 53', ' Set_Dim_B=-1,Set_Dim_C=1 => pass sup: 0.15 conf: 0.95 len: 3, id: 32', ' Set_Dim_C=1 => pass sup: 0.31 conf: 0.95 len: 2, id: 40', ' Set_Dim_C=2,Set_Dim_B=-1 => fail sup: 0.19 conf: 0.95 len: 3, id: 55', ' Set_Dim_C=-1,Set_Dim_B=-1,Datum_probe=-1 => pass sup: 0.09 conf: 0.92 len: 4, id: 0', ' Set_Dim_C=-1,Set_Dim_B=-1 => pass sup: 0.09 conf: 0.92 len: 3, id: 1', ' Set_Dim_C=-1,Datum_probe=-1 => pass sup: 0.12 conf: 0.90 len: 3, id: 2', ' Set_Dim_C=-1 => pass sup: 0.12 conf: 0.90 len: 2, id: 3', ' Set_Dim_C=2,Set_Dim_A=-1 => fail sup: 0.08 conf: 0.87 len: 3, id: 41', ' Diecast_Pivot_2=1,Max_force=-2,Set_Dim_C=2 => fail sup: 0.11 conf: 0.86 len: 4, id: 47', ' Set_Dim_C=2,Max_force=-2 => fail sup: 0.17 conf: 0.85 len: 3, id: 49', ' Set_Dim_A=1,Datum_probe=-1,Max_force=-3 => pass sup: 0.08 conf: 0.85 len: 4, id: 11']\n"
     ]
    }
   ],
   "source": [
    "aa =\" \"\n",
    "dd=[]\n",
    "for  x in range(len(cba1)):\n",
    "    aa += str (cba1[x]).replace(\"{\",\"\").replace(\"}\",\"\").replace(\"Projection1=\",\"\")\n",
    "    dd=aa.split(\"CAR\")\n",
    "print(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid=[]\n",
    "fid01=[]\n",
    "Sup=[]\n",
    "Conf=[]\n",
    "for op in range(len(dd)):\n",
    "    dat=(dd[op].split())\n",
    "    fid+=(dat[0:1])\n",
    "    fid01+=dat[2:3]\n",
    "    Sup+=dat[4:5]\n",
    "    Conf+=dat[6:7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array=[]\n",
    "ok =[]\n",
    "i=0\n",
    "while i < len(fid):\n",
    "    my_array+= fid[i].split()\n",
    "    ok +=[my_array[i]+','+'Null=Null'+','+'Null=Null'+','+'Null=Null'+','+'Null=Null']\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sp=[]\n",
    "KPIV1=[]\n",
    "KPIV2=[]\n",
    "KPIV3=[]\n",
    "KPIV4=[]\n",
    "for i in ok:\n",
    "    Sp1=i.split(',')\n",
    "    KPIV1+=[Sp1[0]]\n",
    "    KPIV2+=[Sp1[1]]\n",
    "    KPIV3+=[Sp1[2]]\n",
    "    KPIV4+=[Sp1[3]]\n",
    "\n",
    "KPIVOK=[KPIV1],[KPIV2],[KPIV3],[KPIV4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataok=[]\n",
    "for i in range(len(KPIVOK)):\n",
    "    dataok+=(KPIVOK[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1=[]\n",
    "for i in (dataok[0]):\n",
    "    sp1+=[(i.split('='))]\n",
    "\n",
    "sp2=[]\n",
    "for i in (dataok[1]):\n",
    "    sp2+=[(i.split('='))]\n",
    "\n",
    "sp3=[]\n",
    "for i in (dataok[2]):\n",
    "    sp3+=[(i.split('='))]\n",
    "\n",
    "sp4=[]\n",
    "for i in (dataok[3]):\n",
    "    sp4+=[(i.split('='))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cl1=[]\n",
    "for i in sp1:\n",
    "    Cl1+=([i[0]])\n",
    "\n",
    "Cl2=[]\n",
    "for i in sp1:\n",
    "    Cl2+=([i[1]])\n",
    "\n",
    "Cl3=[]\n",
    "for i in sp2:\n",
    "    Cl3+=([i[0]])\n",
    "\n",
    "Cl4=[]\n",
    "for i in sp2:\n",
    "    Cl4+=([i[1]])\n",
    "\n",
    "Cl5=[]\n",
    "for i in sp3:\n",
    "    Cl5+=([i[0]])\n",
    "\n",
    "Cl6=[]\n",
    "for i in sp3:\n",
    "    Cl6+=([i[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datum_probe\n",
      "Set_Dim_C\n",
      "Set_Dim_C\n",
      "-\n",
      "Max_force\n",
      "Set_Dim_C\n",
      "Set_Dim_C\n",
      "-\n",
      "-\n",
      "-\n",
      "Set_Dim_B\n",
      "-\n",
      "Set_Dim_C\n",
      "-\n",
      "-\n",
      "-\n",
      "Datum_probe\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "Set_Dim_C\n",
      "-\n",
      "Max_force\n"
     ]
    }
   ],
   "source": [
    "for i in Cl5:\n",
    "    CL05=i.replace(\"Null\", \"-\")\n",
    "    print(CL05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexok=[]\n",
    "for i in range(len(my_array)):\n",
    "    indexok+=([i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "displaying the dataframe with data as record\n",
      "          Date              betweenDate   Model  Line  Rangeindex Datum_probe  \\\n",
      "21  2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10          22               \n",
      "20  2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10          21               \n",
      "15  2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10          16               \n",
      "10  2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10          11               \n",
      "22  2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10          23               \n",
      "12  2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10          13               \n",
      "0   2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10           1          -1   \n",
      "19  2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10          20               \n",
      "18  2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10          19          -1   \n",
      "17  2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10          18               \n",
      "16  2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10          17          -1   \n",
      "14  2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10          15               \n",
      "13  2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10          14               \n",
      "11  2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10          12               \n",
      "8   2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10           9               \n",
      "7   2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10           8               \n",
      "6   2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10           7          -1   \n",
      "5   2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10           6          -1   \n",
      "4   2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10           5          -1   \n",
      "3   2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10           4               \n",
      "2   2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10           3          -1   \n",
      "1   2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10           2               \n",
      "9   2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10          10          -1   \n",
      "23  2023-06-20  2023-01-21 - 2023-06-19  LONGSP  3-10          24          -1   \n",
      "\n",
      "   Max_force Set_Dim_A Set_Dim_B Set_Dim_C Diecast_Pivot_2 Projection Support  \\\n",
      "21        -2                             2               1       fail    0.11   \n",
      "20                  -1                   2                       fail    0.08   \n",
      "15                            -1         2                       fail    0.19   \n",
      "10        -2                  -1         2                       fail    0.12   \n",
      "22        -2                             2                       fail    0.17   \n",
      "12                            -1         2               1       fail    0.12   \n",
      "0                    1         1                                 pass    0.09   \n",
      "19                                      -1                       pass    0.12   \n",
      "18                                      -1                       pass    0.12   \n",
      "17                            -1        -1                       pass    0.09   \n",
      "16                            -1        -1                       pass    0.09   \n",
      "14                                       1                       pass    0.31   \n",
      "13                            -1         1                       pass    0.15   \n",
      "11                                       1              -1       pass    0.11   \n",
      "8         -3                             1                       pass    0.11   \n",
      "7                    1                   1                       pass    0.17   \n",
      "6                    1                   1                       pass    0.17   \n",
      "5                                        1              -1       pass    0.11   \n",
      "4         -3                             1                       pass    0.11   \n",
      "3                              1         1                       pass    0.14   \n",
      "2                              1         1                       pass    0.14   \n",
      "1                    1         1         1                       pass    0.09   \n",
      "9                                        1                       pass    0.30   \n",
      "23        -3         1                                           pass    0.08   \n",
      "\n",
      "   Confidence  \n",
      "21       0.86  \n",
      "20       0.87  \n",
      "15       0.95  \n",
      "10       0.95  \n",
      "22       0.85  \n",
      "12       0.95  \n",
      "0        0.98  \n",
      "19       0.90  \n",
      "18       0.90  \n",
      "17       0.92  \n",
      "16       0.92  \n",
      "14       0.95  \n",
      "13       0.95  \n",
      "11       0.95  \n",
      "8        0.97  \n",
      "7        0.97  \n",
      "6        0.97  \n",
      "5        0.97  \n",
      "4        0.97  \n",
      "3        0.98  \n",
      "2        0.98  \n",
      "1        0.98  \n",
      "9        0.95  \n",
      "23       0.85  \n",
      "-------------------------------Converting into csv file with a new a new file name ------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "indexok=[]\n",
    "for i in range(len(my_array)):\n",
    "    indexok+=([i+1])\n",
    "data ={\n",
    "'Date':Date,\n",
    "'betweenDate':str(Startdate)+' - '+str(finishDate),\n",
    "'Model':Model,\n",
    "'Line':Line,\n",
    "'Rangeindex':indexok,\n",
    "'Cl1':Cl1,\n",
    "'Cl2':Cl2,\n",
    "'Cl3':Cl3,\n",
    "'Cl4':Cl4,\n",
    "'Cl5':Cl5,\n",
    "'Cl6':Cl6,\n",
    "'Projection':fid01,\n",
    "'Support':Sup,\n",
    "'Confidence':Conf,}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.loc[df['Cl1'] == 'Datum_probe', 'Datum_probe'] = df['Cl2']\n",
    "df.loc[df['Cl3'] == 'Datum_probe', 'Datum_probe'] = df['Cl4']\n",
    "df.loc[df['Cl5'] == 'Datum_probe', 'Datum_probe'] = df['Cl6']\n",
    "\n",
    "df.loc[df['Cl1'] == 'Max_force', 'Max_force'] = df['Cl2']\n",
    "df.loc[df['Cl3'] == 'Max_force', 'Max_force'] = df['Cl4']\n",
    "df.loc[df['Cl5'] == 'Max_force', 'Max_force'] = df['Cl6']\n",
    "\n",
    "df.loc[df['Cl1'] == 'Set_Dim_A', 'Set_Dim_A'] = df['Cl2']\n",
    "df.loc[df['Cl3'] == 'Set_Dim_A', 'Set_Dim_A'] = df['Cl4']\n",
    "df.loc[df['Cl5'] == 'Set_Dim_A', 'Set_Dim_A'] = df['Cl6']\n",
    "\n",
    "df.loc[df['Cl1'] == 'Set_Dim_B', 'Set_Dim_B'] = df['Cl2']\n",
    "df.loc[df['Cl3'] == 'Set_Dim_B', 'Set_Dim_B'] = df['Cl4']\n",
    "df.loc[df['Cl5'] == 'Set_Dim_B', 'Set_Dim_B'] = df['Cl6']\n",
    "\n",
    "df.loc[df['Cl1'] == 'Set_Dim_C', 'Set_Dim_C'] = df['Cl2']\n",
    "df.loc[df['Cl3'] == 'Set_Dim_C', 'Set_Dim_C'] = df['Cl4']\n",
    "df.loc[df['Cl5'] == 'Set_Dim_C', 'Set_Dim_C'] = df['Cl6']\n",
    "\n",
    "df.loc[df['Cl1'] == 'Diecast_Pivot_2', 'Diecast_Pivot_2'] = df['Cl2']\n",
    "df.loc[df['Cl3'] == 'Diecast_Pivot_2', 'Diecast_Pivot_2'] = df['Cl4']\n",
    "df.loc[df['Cl5'] == 'Diecast_Pivot_2', 'Diecast_Pivot_2'] = df['Cl6']\n",
    "\n",
    "df = df.sort_values('Projection')\n",
    "\n",
    "\n",
    "# for column\n",
    "# df['Datum_probe'] = df['Datum_probe'].replace(np.nan, 0)\n",
    "\n",
    "# for whole dataframe\n",
    "df = df.replace(np.nan, '')\n",
    "# inplace\n",
    "df.replace(np.nan, 0, inplace=True)\n",
    "\n",
    "df = pd.DataFrame(df,columns=['Date','betweenDate','Model','Line','Rangeindex','Datum_probe','Max_force','Set_Dim_A','Set_Dim_B','Set_Dim_C','Diecast_Pivot_2','Projection','Support','Confidence'])\n",
    "print(\"displaying the dataframe with data as record\")\n",
    "print(df)\n",
    "print(\"-------------------------------Converting into csv file with a new a new file name ------------------------------------\")\n",
    "# df.to_csv(\"C:\\\\Users\\\\IT\\\\Desktop\\\\Date ML\\\\3-10 KPIV.csv\")\n",
    "# df=pd.read_csv(\"C:\\\\Users\\\\IT\\\\Desktop\\\\Date ML\\\\3-10 KPIV.csv\")\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "# Insert Dataframe into SQL Server:\n",
    "for index, row in df.iterrows():\n",
    "     cursor.execute(\"INSERT INTO [DataforAnalysis].[dbo].[Sample_Data_ML_TEST](Date,betweenDate,Model,Line,Rangeindex,Datum_probe,Max_force,Set_Dim_A,Set_Dim_B,Set_Dim_C,Diecast_Pivot_2,Projection,Support,Confidence) values ('\"+str(row.Date)+\"','\"+row.betweenDate+\"','\"+row.Model+\"','\"+row.Line+\"','\"+str(row.Rangeindex)+\"','\"+str(row.Datum_probe)+\"','\"+str(row.Max_force)+\"','\"+str(row.Set_Dim_A)+\"','\"+str(row.Set_Dim_B)+\"','\"+str(row.Set_Dim_C)+\"','\"+str(row.Diecast_Pivot_2)+\"','\"+str(row.Projection)+\"','\"+str(row.Support)+\"','\"+str(row.Confidence)+\"')\")\n",
    "     # ,(row.Date,row.betweenDate,row.Model,)\n",
    "                    # ('\"+row.Date+\"','\"+row.betweenDate+\"','\"+row.Model+\"','\"+row.Line+\"','\"+row.Datum_probe+\"','\"+ a +\"','\"+row.Set_Dim_A+\"','\"+row.Set_Dim_B+\"','\"+row.Set_Dim_C+\"','\"+row.Diecast_Pivot_2+\"','\"+row.Projection+\"','\"+row.Support+\"','\"+row.Confidence+\"')\")\n",
    "cnxn.commit()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\ML\\src\\ARM_3-10_up 18-05-23.ipynb Cell 31\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#X42sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#X42sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m data_join \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#X42sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m9\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m4\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m6\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m13\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m20\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m19\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m],  \u001b[39m# ให้ค่า None ใน 'id'\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#X42sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39msup\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.06\u001b[39m, \u001b[39m0.07\u001b[39m, \u001b[39m0.05\u001b[39m, \u001b[39m0.06\u001b[39m, \u001b[39m0.08\u001b[39m, \u001b[39m0.09\u001b[39m, \u001b[39m0.1\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#X42sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mProjection1\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mPass\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfail\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPass\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfail\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPass\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfail\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPass\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#X42sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m }\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#X42sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m df2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(data_join)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#X42sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m df2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data_join)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ML/src/ARM_3-10_up%2018-05-23.ipynb#X42sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m df2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data_join)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:663\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    657\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    658\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    659\u001b[0m     )\n\u001b[0;32m    661\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    662\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 663\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    664\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    665\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    119\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# สร้าง DataFrame แรก\n",
    "data_KPIV = {\n",
    "    'KPIV': ['Set_Dim_C', 'Set_Dim_B', 'Set_Dim_C', 'Set_Dim_C', 'Set_Dim_C', 'Set_Dim_C', 'Set_Dim_C', 'Set_Dim_C'],\n",
    "    'KPIV1': ['3', '-2', '2', '1', '1', '1', '2', '1'],\n",
    "    'KPIV2': ['null', 'Set_Dim_C', 'Set_Dim_A', 'Set_Dim_A', 'Set_Dim_B', 'Set_Dim_B', 'null', 'Set_Dim_A'],\n",
    "    'KPIV3': ['null', '2', '2', '-1', '1', '-1', 'null', '1'],\n",
    "    'KPIV4': ['null', 'Set_Dim_C', 'Set_Dim_A', 'Set_Dim_A', 'Set_Dim_B', 'Set_Dim_B', 'null', 'Set_Dim_A'],\n",
    "    'KPIV5': ['null', '2', '2', '-1', '1', '-1', 'null', '1'],\n",
    "    'id': ['0', '9', '4', '6', '13', '20', '19', None]\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data_KPIV)\n",
    "\n",
    "# สร้าง DataFrame ที่มีคอลัมน์ 'id' เพื่อใช้ในการ join\n",
    "import pandas as pd\n",
    "\n",
    "# สร้าง DataFrame ที่มีคอลัมน์ 'id' เพื่อใช้ในการ join\n",
    "import numpy as np\n",
    "\n",
    "data_join = {\n",
    "    'id': ['0', '9', '4', '6', '13', '20', '19', None],  # ให้ค่า None ใน 'id'\n",
    "    'sup': [0.06, 0.07, 0.05, 0.06, 0.08, 0.09, 0.1],\n",
    "    'conf': [0.95, 0.84, 0.83, 0.80, 0.79, 0.88, 0.87],\n",
    "    'len': [2, 3, 3, 3, 3, 3, 2],\n",
    "    'KPIV': ['Set_Dim_C', 'Set_Dim_B', 'Set_Dim_C', 'Set_Dim_C', 'Set_Dim_C', 'Set_Dim_B', 'Set_Dim_A'],\n",
    "    'KPOV': ['nan', '0', '0', '0', '0', '0', '1'],\n",
    "    'Projection1': ['Pass', 'fail', 'Pass', 'fail', 'Pass', 'fail', 'Pass']\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(data_join)\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(data_join)\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(data_join)\n",
    "\n",
    "# ทำการ merge โดยใช้คอลัมน์ 'id'\n",
    "result_df = df1.merge(df2, on='id')\n",
    "\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Set_Dim_C=3', 'Set_Dim_B=-2', 'Set_Dim_C=2', 'Set_Dim_C=1', 'Set_Dim_C=1', 'Set_Dim_C=1', 'Set_Dim_C=2', 'Set_Dim_C=1'], ['Set_Dim_C=2', 'Set_Dim_A=2', 'Set_Dim_A=-1', 'Set_Dim_B=1', 'Set_Dim_B=-1', 'Set_Dim_A=1'], ['Set_Dim_A=1'], []]\n"
     ]
    }
   ],
   "source": [
    "KPIV_list = ['Set_Dim_C=3', 'Set_Dim_B=-2,Set_Dim_C=2', 'Set_Dim_C=2,Set_Dim_A=2', 'Set_Dim_C=1,Set_Dim_A=-1', 'Set_Dim_C=1,Set_Dim_B=1', 'Set_Dim_C=1,Set_Dim_B=-1,Set_Dim_A=1', 'Set_Dim_C=2', 'Set_Dim_C=1,Set_Dim_A=1']\n",
    "max_len = 4\n",
    "\n",
    "# สร้างลิสต์เริ่มต้นสำหรับทุก KPIV\n",
    "all_KPIV_list = [[] for _ in range(max_len)]\n",
    "\n",
    "# ลูปเพื่อวนรวมข้อมูลใน KPIV_list ไปยัง all_KPIV_list\n",
    "for item in KPIV_list:\n",
    "    KPIV_values = item.split(',')  # แยกค่า KPIV ในรูปแบบ 'KPIV1=1,KPIV2=2,...'\n",
    "    for i, KPIV_value in enumerate(KPIV_values):\n",
    "        all_KPIV_list[i].append(KPIV_value)\n",
    "\n",
    "# ตอนนี้ all_KPIV_list จะมีข้อมูลของทุก KPIV แยกตามเลขลำดับ (0, 1, 2, 3, ...)\n",
    "print(all_KPIV_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id   sup  conf  len  Set_Dim_C  Set_Dim_B  Set_Dim_A Projection1\n",
      "0   0  0.06  0.95    2         -1        NaN        NaN        fail\n",
      "1   1  0.13  0.97    2         -1        NaN        1.0        Pass\n",
      "2   2  0.05  0.82    3          2        NaN        NaN        Pass\n",
      "3   3  0.06  0.82    3          2        NaN        2.0        fail\n",
      "4   4  0.06  0.84    3          2       -2.0        NaN        Pass\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# สร้าง DataFrame ตามข้อมูลที่คุณมี\n",
    "data = {\n",
    "    'sup': [0.13, 0.06, 0.06, 0.06, 0.05],\n",
    "    'conf': [0.97, 0.95, 0.84, 0.82, 0.82],\n",
    "    'len': [2, 2, 3, 3, 3],\n",
    "    'id': [3, 0, 8, 6, 4],\n",
    "    'Set_Dim_C': [-1, -1, 2, 2, 2],\n",
    "    'Set_Dim_B': [None, None, -2, None, None],\n",
    "    'Set_Dim_A': [1, None, None, 2, None],\n",
    "    'Projection1': ['Pass', 'fail', 'Pass', 'fail', 'Pass']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ปรับแก้ค่าในคอลัมน์ 'id' ให้เหมือนกันในแต่ละแถว\n",
    "df['id'] = df.groupby('id').ngroup()\n",
    "\n",
    "# รวมข้อมูลโดย groupby ด้วยคอลัมน์ 'id' และรวมค่าเฉลี่ยของคอลัมน์อื่น ๆ\n",
    "result_df = df.groupby('id').agg({\n",
    "    'sup': 'sum',\n",
    "    'conf': 'mean',\n",
    "    'len': 'sum',\n",
    "    'Set_Dim_C': 'max',\n",
    "    'Set_Dim_B': 'max',\n",
    "    'Set_Dim_A': 'max',\n",
    "    'Projection1': 'first'\n",
    "}).reset_index()\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id   sup conf len  Set_Dim_C  Set_Dim_B  Set_Dim_A Projection1\n",
      "0      1  0.05    3   3         -1       -1.0        NaN        Pass\n",
      "1      3  0.13    2   2         -1        NaN        NaN        Pass\n",
      "2      0  0.06    2   2          3        NaN        NaN        fail\n",
      "3      8  0.06    3   3          2       -2.0        NaN        fail\n",
      "4      4  0.06    3   3          2        NaN        2.0        fail\n",
      "5     12  0.08    3   3          1        1.0        NaN        Pass\n",
      "6     19  0.06    4   4          1       -1.0        1.0        Pass\n",
      "7      6  0.06    3   3          1        NaN       -1.0        Pass\n",
      "8     18  0.28    2   2          2        NaN        NaN        fail\n",
      "9     20  0.11    3   3          1       -1.0        NaN        Pass\n",
      "10    21  0.15    3   3          1        NaN        1.0        Pass\n",
      "11  None  0.27    2   2          1        NaN        NaN        Pass\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# รายการข้อมูล KPIV\n",
    "KPIV_list = ['Set_Dim_C=-1,Set_Dim_B=-1', 'Set_Dim_C=-1', 'Set_Dim_C=3', 'Set_Dim_C=2,Set_Dim_B=-2', 'Set_Dim_C=2,Set_Dim_A=2',\n",
    "             'Set_Dim_C=1,Set_Dim_B=1', 'Set_Dim_C=1,Set_Dim_A=1,Set_Dim_B=-1', 'Set_Dim_C=1,Set_Dim_A=-1', 'Set_Dim_C=2',\n",
    "             'Set_Dim_C=1,Set_Dim_B=-1', 'Set_Dim_C=1,Set_Dim_A=1', 'Set_Dim_C=1']\n",
    "\n",
    "# รายการข้อมูล KPOV\n",
    "KPOV_list = ['Projection1=Pass', 'Projection1=Pass', 'Projection1=fail', 'Projection1=fail', 'Projection1=fail',\n",
    "             'Projection1=Pass', 'Projection1=Pass', 'Projection1=Pass', 'Projection1=fail', 'Projection1=Pass',\n",
    "             'Projection1=Pass', 'Projection1=Pass']\n",
    "\n",
    "# รายการข้อมูล sup\n",
    "sup_list = ['0.05 conf: 0.97 len: 3', '0.13 conf: 0.97 len: 2', '0.06 conf: 0.95 len: 2', '0.06 conf: 0.84 len: 3',\n",
    "            '0.06 conf: 0.84 len: 3', '0.08 conf: 0.80 len: 3', '0.06 conf: 0.79 len: 4', '0.06 conf: 0.79 len: 3',\n",
    "            '0.28 conf: 0.78 len: 2', '0.11 conf: 0.75 len: 3', '0.15 conf: 0.73 len: 3', '0.27 conf: 0.72 len: 2']\n",
    "\n",
    "# แยกค่า 'sup', 'conf', และ 'len' จากรายการ 'sup_list'\n",
    "sup_values = [sup.split(' ')[0] for sup in sup_list]\n",
    "conf_values = [conf.split(' ')[2] for conf in conf_list]\n",
    "len_values = [len_value for len_value in len_list]\n",
    "\n",
    "# แยกค่า KPIV และ KPOV จากรายการ KPIV_list และ KPOV_list\n",
    "KPIV_values = [item.split(',') for item in KPIV_list]\n",
    "KPOV_values = [item.split('=')[1] for item in KPOV_list]\n",
    "\n",
    "# สร้าง DataFrame จากข้อมูล\n",
    "data = {\n",
    "    'id': id_list,\n",
    "    'sup': sup_values,\n",
    "    'conf': conf_values,\n",
    "    'len': len_values,\n",
    "    'Set_Dim_C': [next((int(value.split('=')[1]) for value in KPIV if 'Set_Dim_C' in value), None) for KPIV in KPIV_values],\n",
    "    'Set_Dim_B': [next((int(value.split('=')[1]) for value in KPIV if 'Set_Dim_B' in value), None) for KPIV in KPIV_values],\n",
    "    'Set_Dim_A': [next((int(value.split('=')[1]) for value in KPIV if 'Set_Dim_A' in value), None) for KPIV in KPIV_values],\n",
    "    'Projection1': [value for value in KPOV_values]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# แสดง DataFrame\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99e4a2a19c08b165697a52cd79a4815ca9063c5131d2540ea9514263faee8422"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
