{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "Startdate=datetime.datetime.now().date()-datetime.timedelta(30)\n",
    "finishDate=datetime.datetime.now().date()-datetime.timedelta(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date + 1 day: 2023-08-29\n",
      "Empty DataFrame\n",
      "Columns: [Date, %Yield, Cycle_time (sec), Down time (min), AVG, STD, CPK, Model, Machine, Line, Parameter]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_16832\\2215618350.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  max_date_df = pd.read_sql(max_date_query, cnxn)\n",
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_16832\\2215618350.py:112: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  datasets = pd.read_sql(query, cnxn)\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "# Some other example server values are\n",
    "# server = 'localhost\\sqlexpress' # for a named instance\n",
    "# server = 'myserver,port' # to specify an alternate port\n",
    "server = '192.168.101.219' \n",
    "database = 'DataforAnalysis' \n",
    "username = 'DATALYZER' \n",
    "password = 'NMB54321'  \n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "# select 26 rows from SQL table to insert in dataframe.\n",
    "# Query to get the maximum date\n",
    "max_date_query = \"\"\"\n",
    "    SELECT DATEADD(day, 1, MAX([Date])) as MaxDate\n",
    "    FROM [DataforAnalysis].[dbo].[Store_SPC];\n",
    "\"\"\"\n",
    "max_date_df = pd.read_sql(max_date_query, cnxn)\n",
    "\n",
    "# Printing the maximum date with one day added\n",
    "max_date_plus_1 = max_date_df['MaxDate'][0]\n",
    "print(f\"Maximum Date + 1 day: {max_date_plus_1}\")\n",
    "\n",
    "query = f\"\"\"\n",
    "        DECLARE @DynamicSQL AS NVARCHAR(max),\n",
    " @Start NVARCHAR(30) = '{max_date_plus_1}',\n",
    " @End NVARCHAR(30) = '{finishDate}',\n",
    " @Parameter NVARCHAR(30) = 'Set_Dim';\n",
    "\n",
    "-- CTE แรก\n",
    "WITH BarcodeThan100 AS (\n",
    "    SELECT [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] AS [Date],\n",
    "           COUNT([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Barcode]) AS [countBarcode]\n",
    "    FROM [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester]\n",
    "    INNER JOIN [TransportData].[dbo].[Master_matchings]\n",
    "        ON [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Model = [TransportData].[dbo].[Master_matchings].Model\n",
    "    WHERE [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] BETWEEN @Start AND @End\n",
    "\n",
    "        AND [TransportData].[dbo].[Master_matchings].[createdAt] = (\n",
    "            SELECT MAX([TransportData].[dbo].[Master_matchings].[createdAt])\n",
    "            FROM [TransportData].[dbo].[Master_matchings]\n",
    "        )\n",
    "    GROUP BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date]\n",
    "),\n",
    "XT AS (\n",
    "    SELECT [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] AS [Date],\n",
    "           CASE WHEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME)) < 120\n",
    "                THEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME))\n",
    "                WHEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME)) >= 120\n",
    "                THEN 0\n",
    "           END AS [C/T in sec],\n",
    "           CASE WHEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME)) >= 120\n",
    "                THEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME))\n",
    "                WHEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME)) < 120\n",
    "                THEN 0\n",
    "           END AS [D/T],\n",
    "           [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Set_Dim AS [Parameter],\n",
    "           [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Model] AS [model],\n",
    "           [TransportData].[dbo].[Master_matchings].LSL AS [LSL],\n",
    "           [TransportData].[dbo].[Master_matchings].CL AS [CL],\n",
    "           [TransportData].[dbo].[Master_matchings].USL AS [USL],\n",
    "           [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Machine_no] AS [MC],\n",
    "           [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Barcode],\n",
    "           [Line]\n",
    "    FROM BarcodeThan100\n",
    "    LEFT JOIN [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester]\n",
    "        ON BarcodeThan100.Date = [Dynamic_Parallelism_Tester].Date\n",
    "    INNER JOIN [TransportData].[dbo].[Master_matchings]\n",
    "        ON [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Model = [TransportData].[dbo].[Master_matchings].Model\n",
    "    WHERE [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] BETWEEN @Start AND @End\n",
    "        AND [TransportData].[dbo].[Master_matchings].[Parameter] = @Parameter\n",
    "        AND [TransportData].[dbo].[Master_matchings].[createdAt] = (\n",
    "            SELECT MAX([TransportData].[dbo].[Master_matchings].[createdAt])\n",
    "            FROM [TransportData].[dbo].[Master_matchings]\n",
    "        )\n",
    "        AND countBarcode > 100\n",
    "        AND Operator = 'Operator'\n",
    ")\n",
    ", XO AS (\n",
    "    SELECT [Date] AS [Date],\n",
    "           CAST(CONVERT(FLOAT, COUNT(CASE WHEN [Parameter] >= [LSL] AND [Parameter] <= [USL] THEN 1 ELSE NULL END)) /\n",
    "                CONVERT(FLOAT, COUNT(CASE WHEN [Parameter] >= [LSL] AND [Parameter] <= [USL] THEN 1 ELSE NULL END) +\n",
    "                COUNT(CASE WHEN [Parameter] < [LSL] OR [Parameter] > [USL] THEN 1 ELSE NULL END)) * 100 AS DECIMAL(10, 2)) AS [%Yield],\n",
    "           CAST(CONVERT(FLOAT, SUM([C/T in sec])) / COUNT([C/T in sec]) AS DECIMAL(10, 2)) AS [Cycle_time (sec)],\n",
    "           CAST(CONVERT(FLOAT, SUM([D/T])) / 60 AS DECIMAL(10, 0)) AS [Down time (min)],\n",
    "           CAST(AVG([Parameter]) AS DECIMAL(10, 3)) AS [AVG],\n",
    "           CAST(STDEV([Parameter]) AS DECIMAL(10, 4)) AS [STD],\n",
    "           CASE WHEN (CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2)) <\n",
    "                     CAST(CONVERT(FLOAT, ((AVG([Parameter]) - [LSL]) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))) OR\n",
    "                    ((CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2)) >\n",
    "                    CAST(CONVERT(FLOAT, ((AVG([Parameter]) - [LSL]) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))) AND [LSL] = 0)\n",
    "                THEN CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))\n",
    "            WHEN CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2)) >\n",
    "                 CAST(CONVERT(FLOAT, ((AVG([Parameter]) - [LSL]) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))\n",
    "                THEN CAST(CONVERT(FLOAT, ((AVG([Parameter]) - [LSL]) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))\n",
    "            WHEN CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2)) =\n",
    "                 CAST(CONVERT(FLOAT, ((AVG([Parameter]) - [LSL]) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))\n",
    "                THEN CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))\n",
    "           END AS [CPK],\n",
    "           [model] AS [Model],\n",
    "           [MC] AS [Machine],\n",
    "           [Line] AS Line\n",
    "    FROM XT\n",
    "    GROUP BY [Date], [model], [LSL], [CL], [USL], [MC], [Line]\n",
    "\tHAVING  STDEV([Parameter]) != 0 and STDEV([Parameter]) is not null\n",
    "\n",
    ")\n",
    "-- คำสั่ง SQL ส่วนอื่น ๆ\n",
    "SELECT [Date], [%Yield], [Cycle_time (sec)], [Down time (min)], [AVG], [STD], [CPK], [Model], [Machine], [Line],@Parameter as Parameter\n",
    "FROM XO;\n",
    "        \"\"\"\n",
    "datasets = pd.read_sql(query, cnxn)\n",
    "print(datasets.head(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_16832\\3032691257.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  datasets = pd.read_sql(query, cnxn)\n"
     ]
    }
   ],
   "source": [
    "# Your existing code here...\n",
    "\n",
    "# Execute the SQL query and store the results in the 'datasets' DataFrame\n",
    "datasets = pd.read_sql(query, cnxn)\n",
    "\n",
    "# Your existing code here...\n",
    "\n",
    "# Establish a new connection for inserting the data into the target table\n",
    "insert_server = '192.168.101.219'\n",
    "insert_database = 'DataforAnalysis'\n",
    "insert_username = 'DATALYZER'\n",
    "insert_password = 'NMB54321'\n",
    "insert_cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+insert_server+';DATABASE='+insert_database+';UID='+insert_username+';PWD='+ insert_password)\n",
    "insert_cursor = insert_cnxn.cursor()\n",
    "\n",
    "# Iterate through the rows of the 'datasets' DataFrame and insert data into the target table\n",
    "for index, row in datasets.iterrows():\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO [DataforAnalysis].[dbo].[Store_SPC] ([Date], [Model], [Line], [Machine], [%Yield], [Cycle_time (sec)],\n",
    "        [Down time (min)], [AVG], [STD], [CPK], [Parameter])\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "    values = (row['Date'], row['Model'], row['Line'], row['Machine'], row['%Yield'], row['Cycle_time (sec)'],\n",
    "              row['Down time (min)'], row['AVG'], row['STD'], row['CPK'], row['Parameter'])\n",
    "    insert_cursor.execute(insert_query, values)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "insert_cursor.commit()\n",
    "insert_cursor.close()\n",
    "insert_cnxn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_16832\\2344026804.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  max_date_df = pd.read_sql(max_date_query, cnxn)\n",
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_16832\\2344026804.py:112: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dataSTD = pd.read_sql(query, cnxn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date + 1 day: 2023-08-29\n",
      "Empty DataFrame\n",
      "Columns: [Date, Model, Line, Machine, %Yield, Cycle_time (sec), Down time (min), AVG, STD, CPK, USL, CL, LSL, Parameter]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "# Some other example server values are\n",
    "# server = 'localhost\\sqlexpress' # for a named instance\n",
    "# server = 'myserver,port' # to specify an alternate port\n",
    "server = '192.168.101.219' \n",
    "database = 'DataforAnalysis' \n",
    "username = 'DATALYZER' \n",
    "password = 'NMB54321'  \n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "# select 26 rows from SQL table to insert in dataframe.\n",
    "# Query to get the maximum date\n",
    "max_date_query = \"\"\"\n",
    "    SELECT DATEADD(day, 1, MAX([Date])) as MaxDate\n",
    "    FROM [DataforAnalysis].[dbo].[SPC_STD_MC];\n",
    "\"\"\"\n",
    "max_date_df = pd.read_sql(max_date_query, cnxn)\n",
    "\n",
    "# Printing the maximum date with one day added\n",
    "max_date_plus_1 = max_date_df['MaxDate'][0]\n",
    "print(f\"Maximum Date + 1 day: {max_date_plus_1}\")\n",
    "\n",
    "query = f\"\"\"\n",
    "  DECLARE @DynamicSQL AS NVARCHAR(max),\n",
    " @Start NVARCHAR(30) = '{max_date_plus_1}',\n",
    " @End NVARCHAR(30) = '{finishDate}',\n",
    " @Parameter NVARCHAR(30) = 'Set_Dim';\n",
    "\n",
    "    WITH BarcodeThan100 as(\n",
    "      select [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] as [Date]\n",
    "             ,count([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Barcode]) as  [countBarcode]\n",
    "             from [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester]\n",
    "                INNER JOIN [TransportData].[dbo].[Master_matchings]\n",
    "                ON [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Model = [TransportData].[dbo].[Master_matchings].Model\n",
    "             where [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] BETWEEN  @Start AND  @End\n",
    "             and [TransportData].[dbo].[Master_matchings].[createdAt] = (select max([TransportData].[dbo].[Master_matchings].[createdAt]) from [TransportData].[dbo].[Master_matchings])\n",
    "       group by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date]\n",
    "       )\n",
    "    ,XT (x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11) as\n",
    "        (select [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] as [Date]\n",
    "        ,case when datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time)) < 120\n",
    "        then datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time))\n",
    "        when datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time)) >= 120 then 0 end as [C/T in sec]\n",
    "        ,case when datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time)) >= 120\n",
    "        then datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time))\n",
    "        when datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time)) < 120 then 0 end as [D/T]\n",
    "        ,[DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Set_Dim as [Parameter]\n",
    "        ,[DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Model] as [model]\n",
    "        ,[TransportData].[dbo].[Master_matchings].LSL as [LSL]\n",
    "        ,[TransportData].[dbo].[Master_matchings].CL as [CL]\n",
    "        ,[TransportData].[dbo].[Master_matchings].USL as [USL]\n",
    "        ,'Average' as [AVG]\n",
    "        ,[DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Barcode]\n",
    "\t\t,Line\n",
    "        from BarcodeThan100\n",
    "                                left join [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester]\n",
    "                                on BarcodeThan100.Date = [Dynamic_Parallelism_Tester].Date\n",
    "        INNER JOIN [TransportData].[dbo].[Master_matchings]\n",
    "        ON [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Model = [TransportData].[dbo].[Master_matchings].Model\n",
    "         where [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] BETWEEN  @Start AND  @End\n",
    "        and [TransportData].[dbo].[Master_matchings].[Parameter] = @Parameter\n",
    "        and [TransportData].[dbo].[Master_matchings].[createdAt] = (select max([TransportData].[dbo].[Master_matchings].[createdAt]) from [TransportData].[dbo].[Master_matchings])\n",
    "        and countBarcode >100\n",
    "        and Operator = 'Operator'\n",
    "        ),\n",
    "     XO (x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13) as (\n",
    "    select \n",
    "        x1 as [Date],\n",
    "        ISNULL(cast(convert(float,count(case when x4 >= x6 and x4 <= x8 then 1 else null end))/\n",
    "        convert(float,count(case when x4 >= x6 and x4 <= x8 then 1 else null end)\n",
    "        + count(case when x4 < x6 or x4 > x8 then 1 else null end)) * 100 AS DECIMAL(10, 2)), 0) as [%Yield], -- Replace NULL with 0\n",
    "        ISNULL(cast(convert(float,sum(x2))/count(x2) as DECIMAL(10, 2)), 0) as [Cycle_time (sec)], -- Replace NULL with 0\n",
    "        ISNULL(cast(convert(float,sum(x3))/60 as decimal(10,0)), 0) as [Down time (min)], -- Replace NULL with 0\n",
    "        ISNULL(cast(AVG(x4) as decimal(10,3)), 0) as [AVG], -- Replace NULL with 0\n",
    "        ISNULL(cast(stdev(x4) as decimal(10,4)), 0) as [STD], -- Replace NULL with 0\n",
    "        case when (cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2)) < cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2))) or\n",
    "        ((cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2)) > cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2))) and x6 = 0)\n",
    "        then ISNULL(cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2)), 0) when cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2))\n",
    "        > cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2))\n",
    "        then ISNULL(cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2)), 0) when cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2))\n",
    "        = cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2))\n",
    "        then ISNULL(cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2)), 0) end as [CPK],\n",
    "        x5 as [Model],\n",
    "        x6 as [LSL],\n",
    "        x7 as [CL],\n",
    "        x8 as [USL],\n",
    "        x9 as [Machine],\n",
    "        x11 as Line\n",
    "    from XT\n",
    "    group by x1,x5,x6,x7,x8,x9,x11\n",
    "    having STDEV(x4) != 0 and STDEV(x4) is not null\n",
    ")\n",
    "      select \n",
    "      XO.x1 as [Date]\n",
    "\t  ,XO.x8 as [Model]\n",
    "      ,XO.x13 as Line\n",
    "      ,XO.x12 as [Machine]\n",
    "      ,XO.x2 as [%Yield]\n",
    "      ,XO.x3 as [Cycle_time (sec)]\n",
    "      ,XO.x4 as [Down time (min)]\n",
    "      ,XO.x5 as [AVG]\n",
    "      ,XO.x6 as [STD]\n",
    "      ,XO.x7 as [CPK]\n",
    "    \n",
    "      ,x11 as [USL]\n",
    "      ,x10 as [CL]\n",
    "      ,x9 as [LSL]\n",
    "\t  ,@Parameter as Parameter\n",
    "      from XO\n",
    "        \"\"\"\n",
    "dataSTD = pd.read_sql(query, cnxn)\n",
    "print(dataSTD.head(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_16832\\4262995815.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  datasets = pd.read_sql(query, cnxn)\n"
     ]
    }
   ],
   "source": [
    "# Your existing code here...\n",
    "\n",
    "# Execute the SQL query and store the results in the 'datasets' DataFrame\n",
    "datasets = pd.read_sql(query, cnxn)\n",
    "\n",
    "# Your existing code here...\n",
    "\n",
    "# Establish a new connection for inserting the data into the target table\n",
    "insert_server = '192.168.101.219'\n",
    "insert_database = 'DataforAnalysis'\n",
    "insert_username = 'DATALYZER'\n",
    "insert_password = 'NMB54321'\n",
    "insert_cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+insert_server+';DATABASE='+insert_database+';UID='+insert_username+';PWD='+ insert_password)\n",
    "insert_cursor = insert_cnxn.cursor()\n",
    "\n",
    "# Iterate through the rows of the 'datasets' DataFrame and insert data into the target table\n",
    "for index, row in dataSTD.iterrows():\n",
    "    insert_query = f\"\"\"\n",
    "        insert into [DataforAnalysis].[dbo].[SPC_STD_MC] ([Date], [Model], [Line], [Machine], [%Yield], [Cycle_time (sec)],\n",
    "        [Down time (min)], [AVG], [STD], [CPK],[LSL],[CL],[USL],[Parameter])\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? , ? )\n",
    "    \"\"\"\n",
    "    values = (row['Date'], row['Model'], row['Line'], row['Machine'], row['%Yield'], row['Cycle_time (sec)'],\n",
    "              row['Down time (min)'], row['AVG'], row['STD'], row['CPK'],row['LSL'],row['CL'],row['USL'], row['Parameter'])\n",
    "    insert_cursor.execute(insert_query, values)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "insert_cursor.commit()\n",
    "insert_cursor.close()\n",
    "insert_cnxn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
