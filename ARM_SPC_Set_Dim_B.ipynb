{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "Startdate=datetime.datetime.now().date()-datetime.timedelta(30)\n",
    "finishDate=datetime.datetime.now().date()-datetime.timedelta(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_4964\\1646507424.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  max_date_df = pd.read_sql(max_date_query, cnxn)\n",
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_4964\\1646507424.py:112: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  datasets = pd.read_sql(query, cnxn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date + 1 day: 2023-08-29\n",
      "           Date  %Yield  Cycle_time (sec)  Down time (min)    AVG     STD  \\\n",
      "0    2023-08-09  100.00              2.18              0.0  4.447  0.0044   \n",
      "1    2023-08-09  100.00              1.02              0.0  3.188  0.0075   \n",
      "2    2023-08-10   99.93              0.38              0.0  1.346  0.0101   \n",
      "3    2023-08-11   99.76              0.54              0.0  0.838  0.0093   \n",
      "4    2023-08-11   99.37              0.47              0.0  4.456  0.0081   \n",
      "..          ...     ...               ...              ...    ...     ...   \n",
      "128  2023-08-17   99.73              0.74              0.0  1.333  0.0109   \n",
      "129  2023-08-17   99.93              0.76              0.0  1.344  0.0098   \n",
      "130  2023-08-19  100.00              0.74              0.0  1.331  0.0106   \n",
      "131  2023-08-19  100.00              0.61              0.0  3.194  0.0073   \n",
      "132  2023-08-19  100.00              0.74              0.0  3.191  0.0073   \n",
      "\n",
      "      CPK   Model     Machine  Line  Parameter  \n",
      "0    2.83  V15C1D  FB-028-011   2-9  Set_Dim_B  \n",
      "1    1.34  V15C2D  FB-028-006  3-29  Set_Dim_B  \n",
      "2    1.20  ROSE2D  FB-028-032   1-8  Set_Dim_B  \n",
      "3    1.12  EVANBP  FB-028-098  3-17  Set_Dim_B  \n",
      "4    1.24  V15C1D  FB-028-011   2-9  Set_Dim_B  \n",
      "..    ...     ...         ...   ...        ...  \n",
      "128  0.95  ROSE2D  FB-028-010  2-11  Set_Dim_B  \n",
      "129  1.29  ROSE2D  FB-028-032   1-8  Set_Dim_B  \n",
      "130  0.91  ROSE2D  FB-028-010  2-11  Set_Dim_B  \n",
      "131  1.08  V11 2D  FB-028-006  3-29  Set_Dim_B  \n",
      "132  1.26  V15C2D  FB-028-037   1-6  Set_Dim_B  \n",
      "\n",
      "[133 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "# Some other example server values are\n",
    "# server = 'localhost\\sqlexpress' # for a named instance\n",
    "# server = 'myserver,port' # to specify an alternate port\n",
    "server = '192.168.101.219' \n",
    "database = 'DataforAnalysis' \n",
    "username = 'DATALYZER' \n",
    "password = 'NMB54321'  \n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "# select 26 rows from SQL table to insert in dataframe.\n",
    "# Query to get the maximum date\n",
    "max_date_query = \"\"\"\n",
    "    SELECT DATEADD(day, 1, MAX([Date])) as MaxDate\n",
    "    FROM [DataforAnalysis].[dbo].[Store_SPC];\n",
    "\"\"\"\n",
    "max_date_df = pd.read_sql(max_date_query, cnxn)\n",
    "\n",
    "# Printing the maximum date with one day added\n",
    "max_date_plus_1 = max_date_df['MaxDate'][0]\n",
    "print(f\"Maximum Date + 1 day: {max_date_plus_1}\")\n",
    "\n",
    "query = f\"\"\"\n",
    "        DECLARE @DynamicSQL AS NVARCHAR(max),\n",
    " @Start NVARCHAR(30) = '{max_date_plus_1}',\n",
    " @End NVARCHAR(30) = '{finishDate}',\n",
    " @Parameter NVARCHAR(30) = 'Set_Dim_B';\n",
    "\n",
    "-- CTE แรก\n",
    "WITH BarcodeThan100 AS (\n",
    "    SELECT [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] AS [Date],\n",
    "           COUNT([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Barcode]) AS [countBarcode]\n",
    "    FROM [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester]\n",
    "    INNER JOIN [TransportData].[dbo].[Master_matchings]\n",
    "        ON [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Model = [TransportData].[dbo].[Master_matchings].Model\n",
    "    WHERE [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] BETWEEN @Start AND @End\n",
    "\n",
    "        AND [TransportData].[dbo].[Master_matchings].[createdAt] = (\n",
    "            SELECT MAX([TransportData].[dbo].[Master_matchings].[createdAt])\n",
    "            FROM [TransportData].[dbo].[Master_matchings]\n",
    "        )\n",
    "    GROUP BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date]\n",
    "),\n",
    "XT AS (\n",
    "    SELECT [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] AS [Date],\n",
    "           CASE WHEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME)) < 120\n",
    "                THEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME))\n",
    "                WHEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME)) >= 120\n",
    "                THEN 0\n",
    "           END AS [C/T in sec],\n",
    "           CASE WHEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME)) >= 120\n",
    "                THEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME))\n",
    "                WHEN DATEDIFF(SECOND, 0, CAST((LAG([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) OVER (ORDER BY [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] DESC) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) AS TIME)) < 120\n",
    "                THEN 0\n",
    "           END AS [D/T],\n",
    "           [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Set_Dim_B AS [Parameter],\n",
    "           [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Model] AS [model],\n",
    "           [TransportData].[dbo].[Master_matchings].LSL AS [LSL],\n",
    "           [TransportData].[dbo].[Master_matchings].CL AS [CL],\n",
    "           [TransportData].[dbo].[Master_matchings].USL AS [USL],\n",
    "           [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Machine_no] AS [MC],\n",
    "           [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Barcode],\n",
    "           [Line]\n",
    "    FROM BarcodeThan100\n",
    "    LEFT JOIN [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester]\n",
    "        ON BarcodeThan100.Date = [Dynamic_Parallelism_Tester].Date\n",
    "    INNER JOIN [TransportData].[dbo].[Master_matchings]\n",
    "        ON [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Model = [TransportData].[dbo].[Master_matchings].Model\n",
    "    WHERE [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] BETWEEN @Start AND @End\n",
    "        AND [TransportData].[dbo].[Master_matchings].[Parameter] = @Parameter\n",
    "        AND [TransportData].[dbo].[Master_matchings].[createdAt] = (\n",
    "            SELECT MAX([TransportData].[dbo].[Master_matchings].[createdAt])\n",
    "            FROM [TransportData].[dbo].[Master_matchings]\n",
    "        )\n",
    "        AND countBarcode > 100\n",
    "        AND Operator = 'Operator'\n",
    ")\n",
    ", XO AS (\n",
    "    SELECT [Date] AS [Date],\n",
    "           CAST(CONVERT(FLOAT, COUNT(CASE WHEN [Parameter] >= [LSL] AND [Parameter] <= [USL] THEN 1 ELSE NULL END)) /\n",
    "                CONVERT(FLOAT, COUNT(CASE WHEN [Parameter] >= [LSL] AND [Parameter] <= [USL] THEN 1 ELSE NULL END) +\n",
    "                COUNT(CASE WHEN [Parameter] < [LSL] OR [Parameter] > [USL] THEN 1 ELSE NULL END)) * 100 AS DECIMAL(10, 2)) AS [%Yield],\n",
    "           CAST(CONVERT(FLOAT, SUM([C/T in sec])) / COUNT([C/T in sec]) AS DECIMAL(10, 2)) AS [Cycle_time (sec)],\n",
    "           CAST(CONVERT(FLOAT, SUM([D/T])) / 60 AS DECIMAL(10, 0)) AS [Down time (min)],\n",
    "           CAST(AVG([Parameter]) AS DECIMAL(10, 3)) AS [AVG],\n",
    "           CAST(STDEV([Parameter]) AS DECIMAL(10, 4)) AS [STD],\n",
    "           CASE WHEN (CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2)) <\n",
    "                     CAST(CONVERT(FLOAT, ((AVG([Parameter]) - [LSL]) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))) OR\n",
    "                    ((CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2)) >\n",
    "                    CAST(CONVERT(FLOAT, ((AVG([Parameter]) - [LSL]) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))) AND [LSL] = 0)\n",
    "                THEN CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))\n",
    "            WHEN CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2)) >\n",
    "                 CAST(CONVERT(FLOAT, ((AVG([Parameter]) - [LSL]) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))\n",
    "                THEN CAST(CONVERT(FLOAT, ((AVG([Parameter]) - [LSL]) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))\n",
    "            WHEN CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2)) =\n",
    "                 CAST(CONVERT(FLOAT, ((AVG([Parameter]) - [LSL]) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))\n",
    "                THEN CAST(CONVERT(FLOAT, (([USL] - AVG([Parameter])) / (3 * STDEV([Parameter])))) AS DECIMAL(10, 2))\n",
    "           END AS [CPK],\n",
    "           [model] AS [Model],\n",
    "           [MC] AS [Machine],\n",
    "           [Line] AS Line\n",
    "    FROM XT\n",
    "    GROUP BY [Date], [model], [LSL], [CL], [USL], [MC], [Line]\n",
    "\tHAVING  STDEV([Parameter]) != 0 and STDEV([Parameter]) is not null\n",
    "\n",
    ")\n",
    "-- คำสั่ง SQL ส่วนอื่น ๆ\n",
    "SELECT [Date], [%Yield], [Cycle_time (sec)], [Down time (min)], [AVG], [STD], [CPK], [Model], [Machine], [Line],@Parameter as Parameter\n",
    "FROM XO;\n",
    "        \"\"\"\n",
    "datasets = pd.read_sql(query, cnxn)\n",
    "print(datasets.head(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_4964\\3032691257.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  datasets = pd.read_sql(query, cnxn)\n"
     ]
    }
   ],
   "source": [
    "# Your existing code here...\n",
    "\n",
    "# Execute the SQL query and store the results in the 'datasets' DataFrame\n",
    "datasets = pd.read_sql(query, cnxn)\n",
    "\n",
    "# Your existing code here...\n",
    "\n",
    "# Establish a new connection for inserting the data into the target table\n",
    "insert_server = '192.168.101.219'\n",
    "insert_database = 'DataforAnalysis'\n",
    "insert_username = 'DATALYZER'\n",
    "insert_password = 'NMB54321'\n",
    "insert_cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+insert_server+';DATABASE='+insert_database+';UID='+insert_username+';PWD='+ insert_password)\n",
    "insert_cursor = insert_cnxn.cursor()\n",
    "\n",
    "# Iterate through the rows of the 'datasets' DataFrame and insert data into the target table\n",
    "for index, row in datasets.iterrows():\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO [DataforAnalysis].[dbo].[Store_SPC] ([Date], [Model], [Line], [Machine], [%Yield], [Cycle_time (sec)],\n",
    "        [Down time (min)], [AVG], [STD], [CPK], [Parameter])\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "    values = (row['Date'], row['Model'], row['Line'], row['Machine'], row['%Yield'], row['Cycle_time (sec)'],\n",
    "              row['Down time (min)'], row['AVG'], row['STD'], row['CPK'], row['Parameter'])\n",
    "    insert_cursor.execute(insert_query, values)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "insert_cursor.commit()\n",
    "insert_cursor.close()\n",
    "insert_cnxn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_4964\\1707701269.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  max_date_df = pd.read_sql(max_date_query, cnxn)\n",
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_4964\\1707701269.py:112: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dataSTD = pd.read_sql(query, cnxn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date + 1 day: 2023-08-29\n",
      "          Date   Model  Line  Machine  %Yield  Cycle_time (sec)  \\\n",
      "0   2023-08-09  V15C4D  3-22  Average  100.00              0.79   \n",
      "1   2023-08-11  M11P5D  2-14  Average   99.65              0.51   \n",
      "2   2023-08-17  LONGSP   3-6  Average   97.87              0.47   \n",
      "3   2023-08-25  V11 4D  3-22  Average  100.00              1.54   \n",
      "4   2023-08-25  V15C1D   2-9  Average  100.00              2.94   \n",
      "..         ...     ...   ...      ...     ...               ...   \n",
      "78  2023-08-17  V11 4D  3-22  Average  100.00              0.67   \n",
      "79  2023-08-17  V15C2D  3-29  Average   99.95              0.62   \n",
      "80  2023-08-17  V15C4D  3-22  Average   99.93              0.91   \n",
      "81  2023-08-19  V11 2D  3-29  Average  100.00              0.62   \n",
      "82  2023-08-28  EVANBP  2-10  Average  100.00             15.40   \n",
      "\n",
      "    Down time (min)    AVG     STD   CPK     USL      CL     LSL  Parameter  \n",
      "0               0.0  1.761  0.0082  1.49  1.8009  1.7628  1.7247  Set_Dim_B  \n",
      "1               0.0 -0.211  0.0080  0.92 -0.1890 -0.2140 -0.2390  Set_Dim_B  \n",
      "2               0.0  0.515  0.0145  0.86  0.5537  0.5156  0.4775  Set_Dim_B  \n",
      "3               0.0  1.753  0.0079  1.19  1.8009  1.7628  1.7247  Set_Dim_B  \n",
      "4            1279.0  4.457  0.0060  1.60  4.4860  4.4480  4.4100  Set_Dim_B  \n",
      "..              ...    ...     ...   ...     ...     ...     ...        ...  \n",
      "78              0.0  1.756  0.0056  1.88  1.8009  1.7628  1.7247  Set_Dim_B  \n",
      "79              0.0  3.188  0.0115  0.88  3.2181  3.1800  3.1419  Set_Dim_B  \n",
      "80              0.0  1.754  0.0069  1.40  1.8009  1.7628  1.7247  Set_Dim_B  \n",
      "81              0.0  3.194  0.0072  1.09  3.2180  3.1800  3.1420  Set_Dim_B  \n",
      "82              0.0  0.819  0.0080  1.09  0.8687  0.8306  0.7925  Set_Dim_B  \n",
      "\n",
      "[83 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "# Some other example server values are\n",
    "# server = 'localhost\\sqlexpress' # for a named instance\n",
    "# server = 'myserver,port' # to specify an alternate port\n",
    "server = '192.168.101.219' \n",
    "database = 'DataforAnalysis' \n",
    "username = 'DATALYZER' \n",
    "password = 'NMB54321'  \n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "# select 26 rows from SQL table to insert in dataframe.\n",
    "# Query to get the maximum date\n",
    "max_date_query = \"\"\"\n",
    "    SELECT DATEADD(day, 1, MAX([Date])) as MaxDate\n",
    "    FROM [DataforAnalysis].[dbo].[SPC_STD_MC];\n",
    "\"\"\"\n",
    "max_date_df = pd.read_sql(max_date_query, cnxn)\n",
    "\n",
    "# Printing the maximum date with one day added\n",
    "max_date_plus_1 = max_date_df['MaxDate'][0]\n",
    "print(f\"Maximum Date + 1 day: {max_date_plus_1}\")\n",
    "\n",
    "query = f\"\"\"\n",
    "  DECLARE @DynamicSQL AS NVARCHAR(max),\n",
    " @Start NVARCHAR(30) = '{max_date_plus_1}',\n",
    " @End NVARCHAR(30) = '{finishDate}',\n",
    " @Parameter NVARCHAR(30) = 'Set_Dim_B';\n",
    "\n",
    "    WITH BarcodeThan100 as(\n",
    "      select [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] as [Date]\n",
    "             ,count([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Barcode]) as  [countBarcode]\n",
    "             from [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester]\n",
    "                INNER JOIN [TransportData].[dbo].[Master_matchings]\n",
    "                ON [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Model = [TransportData].[dbo].[Master_matchings].Model\n",
    "             where [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] BETWEEN  @Start AND  @End\n",
    "             and [TransportData].[dbo].[Master_matchings].[createdAt] = (select max([TransportData].[dbo].[Master_matchings].[createdAt]) from [TransportData].[dbo].[Master_matchings])\n",
    "       group by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date]\n",
    "       )\n",
    "    ,XT (x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11) as\n",
    "        (select [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] as [Date]\n",
    "        ,case when datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time)) < 120\n",
    "        then datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time))\n",
    "        when datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time)) >= 120 then 0 end as [C/T in sec]\n",
    "        ,case when datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time)) >= 120\n",
    "        then datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time))\n",
    "        when datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time)) < 120 then 0 end as [D/T]\n",
    "        ,[DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Set_Dim_B as [Parameter]\n",
    "        ,[DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Model] as [model]\n",
    "        ,[TransportData].[dbo].[Master_matchings].LSL as [LSL]\n",
    "        ,[TransportData].[dbo].[Master_matchings].CL as [CL]\n",
    "        ,[TransportData].[dbo].[Master_matchings].USL as [USL]\n",
    "        ,'Average' as [AVG]\n",
    "        ,[DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Barcode]\n",
    "\t\t,Line\n",
    "        from BarcodeThan100\n",
    "                                left join [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester]\n",
    "                                on BarcodeThan100.Date = [Dynamic_Parallelism_Tester].Date\n",
    "        INNER JOIN [TransportData].[dbo].[Master_matchings]\n",
    "        ON [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Model = [TransportData].[dbo].[Master_matchings].Model\n",
    "         where [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] BETWEEN  @Start AND  @End\n",
    "        and [TransportData].[dbo].[Master_matchings].[Parameter] = @Parameter\n",
    "        and [TransportData].[dbo].[Master_matchings].[createdAt] = (select max([TransportData].[dbo].[Master_matchings].[createdAt]) from [TransportData].[dbo].[Master_matchings])\n",
    "        and countBarcode >100\n",
    "        and Operator = 'Operator'\n",
    "        ),\n",
    "     XO (x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13) as (\n",
    "    select \n",
    "        x1 as [Date],\n",
    "        ISNULL(cast(convert(float,count(case when x4 >= x6 and x4 <= x8 then 1 else null end))/\n",
    "        convert(float,count(case when x4 >= x6 and x4 <= x8 then 1 else null end)\n",
    "        + count(case when x4 < x6 or x4 > x8 then 1 else null end)) * 100 AS DECIMAL(10, 2)), 0) as [%Yield], -- Replace NULL with 0\n",
    "        ISNULL(cast(convert(float,sum(x2))/count(x2) as DECIMAL(10, 2)), 0) as [Cycle_time (sec)], -- Replace NULL with 0\n",
    "        ISNULL(cast(convert(float,sum(x3))/60 as decimal(10,0)), 0) as [Down time (min)], -- Replace NULL with 0\n",
    "        ISNULL(cast(AVG(x4) as decimal(10,3)), 0) as [AVG], -- Replace NULL with 0\n",
    "        ISNULL(cast(stdev(x4) as decimal(10,4)), 0) as [STD], -- Replace NULL with 0\n",
    "        case when (cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2)) < cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2))) or\n",
    "        ((cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2)) > cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2))) and x6 = 0)\n",
    "        then ISNULL(cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2)), 0) when cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2))\n",
    "        > cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2))\n",
    "        then ISNULL(cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2)), 0) when cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2))\n",
    "        = cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2))\n",
    "        then ISNULL(cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2)), 0) end as [CPK],\n",
    "        x5 as [Model],\n",
    "        x6 as [LSL],\n",
    "        x7 as [CL],\n",
    "        x8 as [USL],\n",
    "        x9 as [Machine],\n",
    "        x11 as Line\n",
    "    from XT\n",
    "    group by x1,x5,x6,x7,x8,x9,x11\n",
    "    having STDEV(x4) != 0 and STDEV(x4) is not null\n",
    ")\n",
    "      select \n",
    "      XO.x1 as [Date]\n",
    "\t  ,XO.x8 as [Model]\n",
    "      ,XO.x13 as Line\n",
    "      ,XO.x12 as [Machine]\n",
    "      ,XO.x2 as [%Yield]\n",
    "      ,XO.x3 as [Cycle_time (sec)]\n",
    "      ,XO.x4 as [Down time (min)]\n",
    "      ,XO.x5 as [AVG]\n",
    "      ,XO.x6 as [STD]\n",
    "      ,XO.x7 as [CPK]\n",
    "    \n",
    "      ,x11 as [USL]\n",
    "      ,x10 as [CL]\n",
    "      ,x9 as [LSL]\n",
    "\t  ,@Parameter as Parameter\n",
    "      from XO\n",
    "        \"\"\"\n",
    "dataSTD = pd.read_sql(query, cnxn)\n",
    "print(dataSTD.head(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_4964\\4262995815.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  datasets = pd.read_sql(query, cnxn)\n"
     ]
    }
   ],
   "source": [
    "# Your existing code here...\n",
    "\n",
    "# Execute the SQL query and store the results in the 'datasets' DataFrame\n",
    "datasets = pd.read_sql(query, cnxn)\n",
    "\n",
    "# Your existing code here...\n",
    "\n",
    "# Establish a new connection for inserting the data into the target table\n",
    "insert_server = '192.168.101.219'\n",
    "insert_database = 'DataforAnalysis'\n",
    "insert_username = 'DATALYZER'\n",
    "insert_password = 'NMB54321'\n",
    "insert_cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+insert_server+';DATABASE='+insert_database+';UID='+insert_username+';PWD='+ insert_password)\n",
    "insert_cursor = insert_cnxn.cursor()\n",
    "\n",
    "# Iterate through the rows of the 'datasets' DataFrame and insert data into the target table\n",
    "for index, row in dataSTD.iterrows():\n",
    "    insert_query = f\"\"\"\n",
    "        insert into [DataforAnalysis].[dbo].[SPC_STD_MC] ([Date], [Model], [Line], [Machine], [%Yield], [Cycle_time (sec)],\n",
    "        [Down time (min)], [AVG], [STD], [CPK],[LSL],[CL],[USL],[Parameter])\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? , ? )\n",
    "    \"\"\"\n",
    "    values = (row['Date'], row['Model'], row['Line'], row['Machine'], row['%Yield'], row['Cycle_time (sec)'],\n",
    "              row['Down time (min)'], row['AVG'], row['STD'], row['CPK'],row['LSL'],row['CL'],row['USL'], row['Parameter'])\n",
    "    insert_cursor.execute(insert_query, values)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "insert_cursor.commit()\n",
    "insert_cursor.close()\n",
    "insert_cnxn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
