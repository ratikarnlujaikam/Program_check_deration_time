{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "Startdate=datetime.datetime.now().date()-datetime.timedelta(30)\n",
    "finishDate=datetime.datetime.now().date()-datetime.timedelta(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date + 1 day: 2023-08-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_9380\\1606050750.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  max_date_df = pd.read_sql(max_date_query, cnxn)\n",
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_9380\\1606050750.py:27: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  datasets = pd.read_sql(query, cnxn)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 27\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMaximum Date + 1 day: \u001b[39m\u001b[39m{\u001b[39;00mmax_date_plus_1\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m query \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[39mEXEC  [DataforAnalysis].[dbo].[FlyHeight] \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmax_date_plus_1\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfinishDate\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFlyHeight\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[39m        \u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m---> 27\u001b[0m datasets \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_sql(query, cnxn)\n\u001b[0;32m     28\u001b[0m \u001b[39mprint\u001b[39m(datasets\u001b[39m.\u001b[39mhead(\u001b[39m100000\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\sql.py:564\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    561\u001b[0m pandas_sql \u001b[39m=\u001b[39m pandasSQL_builder(con)\n\u001b[0;32m    563\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[1;32m--> 564\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mread_query(\n\u001b[0;32m    565\u001b[0m         sql,\n\u001b[0;32m    566\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[0;32m    567\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    568\u001b[0m         coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[0;32m    569\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[0;32m    570\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m    571\u001b[0m     )\n\u001b[0;32m    573\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    574\u001b[0m     _is_table_name \u001b[39m=\u001b[39m pandas_sql\u001b[39m.\u001b[39mhas_table(sql)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\sql.py:2079\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[0;32m   2077\u001b[0m args \u001b[39m=\u001b[39m _convert_params(sql, params)\n\u001b[0;32m   2078\u001b[0m cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute(\u001b[39m*\u001b[39margs)\n\u001b[1;32m-> 2079\u001b[0m columns \u001b[39m=\u001b[39m [col_desc[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m col_desc \u001b[39min\u001b[39;00m cursor\u001b[39m.\u001b[39mdescription]\n\u001b[0;32m   2081\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2082\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_query_iterator(\n\u001b[0;32m   2083\u001b[0m         cursor,\n\u001b[0;32m   2084\u001b[0m         chunksize,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2089\u001b[0m         dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   2090\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "# Some other example server values are\n",
    "# server = 'localhost\\sqlexpress' # for a named instance\n",
    "# server = 'myserver,port' # to specify an alternate port\n",
    "server = '192.168.101.219' \n",
    "database = 'DataforAnalysis' \n",
    "username = 'DATALYZER' \n",
    "password = 'NMB54321'  \n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "# select 26 rows from SQL table to insert in dataframe.\n",
    "# Query to get the maximum date\n",
    "max_date_query = \"\"\"\n",
    "    SELECT DATEADD(day, 1, MAX([Date])) as MaxDate\n",
    "    FROM [DataforAnalysis].[dbo].[Store_SPC];\n",
    "\"\"\"\n",
    "max_date_df = pd.read_sql(max_date_query, cnxn)\n",
    "\n",
    "# Printing the maximum date with one day added\n",
    "max_date_plus_1 = max_date_df['MaxDate'][0]\n",
    "print(f\"Maximum Date + 1 day: {max_date_plus_1}\")\n",
    "\n",
    "query = f\"\"\"\n",
    "EXEC  [DataforAnalysis].[dbo].[FlyHeight] '{max_date_plus_1}','{finishDate}','FlyHeight'\n",
    "        \"\"\"\n",
    "datasets = pd.read_sql(query, cnxn)\n",
    "print(datasets.head(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_17720\\3032691257.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  datasets = pd.read_sql(query, cnxn)\n"
     ]
    }
   ],
   "source": [
    "# Your existing code here...\n",
    "\n",
    "# Execute the SQL query and store the results in the 'datasets' DataFrame\n",
    "datasets = pd.read_sql(query, cnxn)\n",
    "\n",
    "# Your existing code here...\n",
    "\n",
    "# Establish a new connection for inserting the data into the target table\n",
    "insert_server = '192.168.101.219'\n",
    "insert_database = 'DataforAnalysis'\n",
    "insert_username = 'DATALYZER'\n",
    "insert_password = 'NMB54321'\n",
    "insert_cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+insert_server+';DATABASE='+insert_database+';UID='+insert_username+';PWD='+ insert_password)\n",
    "insert_cursor = insert_cnxn.cursor()\n",
    "\n",
    "# Iterate through the rows of the 'datasets' DataFrame and insert data into the target table\n",
    "for index, row in datasets.iterrows():\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO [DataforAnalysis].[dbo].[Store_SPC] ([Date], [Model], [Line], [Machine], [%Yield], [Cycle_time (sec)],\n",
    "        [Down time (min)], [AVG], [STD], [CPK], [Parameter])\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "    values = (row['Date'], row['Model'], row['Line'], row['Machine'], row['%Yield'], row['Cycle_time (sec)'],\n",
    "              row['Down time (min)'], row['AVG'], row['STD'], row['CPK'], row['Parameter'])\n",
    "    insert_cursor.execute(insert_query, values)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "insert_cursor.commit()\n",
    "insert_cursor.close()\n",
    "insert_cnxn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date + 1 day: 2023-08-29\n",
      "Empty DataFrame\n",
      "Columns: [Date, Model, Line, Machine, %Yield, Cycle_time (sec), Down time (min), AVG, STD, CPK, USL, CL, LSL, Parameter]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_17720\\613617377.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  max_date_df = pd.read_sql(max_date_query, cnxn)\n",
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_17720\\613617377.py:112: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dataSTD = pd.read_sql(query, cnxn)\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "# Some other example server values are\n",
    "# server = 'localhost\\sqlexpress' # for a named instance\n",
    "# server = 'myserver,port' # to specify an alternate port\n",
    "server = '192.168.101.219' \n",
    "database = 'DataforAnalysis' \n",
    "username = 'DATALYZER' \n",
    "password = 'NMB54321'  \n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "# select 26 rows from SQL table to insert in dataframe.\n",
    "# Query to get the maximum date\n",
    "max_date_query = \"\"\"\n",
    "    SELECT DATEADD(day, 1, MAX([Date])) as MaxDate\n",
    "    FROM [DataforAnalysis].[dbo].[SPC_STD_MC];\n",
    "\"\"\"\n",
    "max_date_df = pd.read_sql(max_date_query, cnxn)\n",
    "\n",
    "# Printing the maximum date with one day added\n",
    "max_date_plus_1 = max_date_df['MaxDate'][0]\n",
    "print(f\"Maximum Date + 1 day: {max_date_plus_1}\")\n",
    "\n",
    "query = f\"\"\"\n",
    "  DECLARE @DynamicSQL AS NVARCHAR(max),\n",
    " @Start NVARCHAR(30) = '{max_date_plus_1}',\n",
    " @End NVARCHAR(30) = '{finishDate}',\n",
    " @Parameter NVARCHAR(30) = 'Parallelism';\n",
    "\n",
    "    WITH BarcodeThan100 as(\n",
    "      select [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] as [Date]\n",
    "             ,count([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Barcode]) as  [countBarcode]\n",
    "             from [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester]\n",
    "                INNER JOIN [TransportData].[dbo].[Master_matchings]\n",
    "                ON [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Model = [TransportData].[dbo].[Master_matchings].Model\n",
    "             where [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] BETWEEN  @Start AND  @End\n",
    "             and [TransportData].[dbo].[Master_matchings].[createdAt] = (select max([TransportData].[dbo].[Master_matchings].[createdAt]) from [TransportData].[dbo].[Master_matchings])\n",
    "       group by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date]\n",
    "       )\n",
    "    ,XT (x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11) as\n",
    "        (select [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] as [Date]\n",
    "        ,case when datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time)) < 120\n",
    "        then datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time))\n",
    "        when datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time)) >= 120 then 0 end as [C/T in sec]\n",
    "        ,case when datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time)) >= 120\n",
    "        then datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time))\n",
    "        when datediff(SECOND,0,cast((lag([DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) over (order by [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time] desc) - [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Time]) as time)) < 120 then 0 end as [D/T]\n",
    "        ,[DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Parallelism as [Parameter]\n",
    "        ,[DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Model] as [model]\n",
    "        ,[TransportData].[dbo].[Master_matchings].LSL as [LSL]\n",
    "        ,[TransportData].[dbo].[Master_matchings].CL as [CL]\n",
    "        ,[TransportData].[dbo].[Master_matchings].USL as [USL]\n",
    "        ,'Average' as [AVG]\n",
    "        ,[DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Barcode]\n",
    "\t\t,Line\n",
    "        from BarcodeThan100\n",
    "                                left join [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester]\n",
    "                                on BarcodeThan100.Date = [Dynamic_Parallelism_Tester].Date\n",
    "        INNER JOIN [TransportData].[dbo].[Master_matchings]\n",
    "        ON [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].Model = [TransportData].[dbo].[Master_matchings].Model\n",
    "         where [DataforAnalysis].[dbo].[Dynamic_Parallelism_Tester].[Date] BETWEEN  @Start AND  @End\n",
    "        and [TransportData].[dbo].[Master_matchings].[Parameter] = @Parameter\n",
    "        and [TransportData].[dbo].[Master_matchings].[createdAt] = (select max([TransportData].[dbo].[Master_matchings].[createdAt]) from [TransportData].[dbo].[Master_matchings])\n",
    "        and countBarcode >100\n",
    "        and Operator = 'Operator'\n",
    "        ),\n",
    "      XO (x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13) as(\n",
    "      select x1 as [Date]\n",
    "      ,cast(convert(float,count(case when x4 >= x6 and x4 <= x8 then 1 else null end))/\n",
    "      convert(float,count(case when x4 >= x6 and x4 <= x8 then 1 else null end)\n",
    "      + count(case when x4 < x6 or x4 > x8 then 1 else null end)) * 100 AS DECIMAL(10, 2) ) as [%Yield]\n",
    "      ,cast(convert(float,sum(x2))/count(x2) as DECIMAL(10, 2)) as [Cycle_time (sec)]\n",
    "      ,cast(convert(float,sum(x3))/60 as decimal(10,0)) as [Down time (min)]\n",
    "      ,cast(AVG(x4) as decimal(10,3)) as [AVG]\n",
    "      ,cast(stdev(x4) as decimal(10,4)) as [STD]\n",
    "      ,case when (cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2)) < cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2))) or\n",
    "      ((cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2)) > cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2))) and x6 = 0)\n",
    "      then cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2)) when cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2))\n",
    "      > cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2))\n",
    "      then cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2)) when cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2))\n",
    "      = cast(convert(float,((AVG(x4)-x6)/(3*STDEV(x4)))) as decimal(10,2))\n",
    "      then cast(convert(float,((x8-AVG(x4))/(3*STDEV(x4)))) as decimal(10,2)) end as [CPK]\n",
    "      ,x5 as [Model]\n",
    "      ,x6 as [LSL]\n",
    "      ,x7 as [CL]\n",
    "      ,x8 as [USL]\n",
    "      ,x9 as [Machine]\n",
    "\t  ,x11 as Line\n",
    "      from XT\n",
    "      group by x1,x5,x6,x7,x8,x9,x11)\n",
    "\n",
    "\n",
    "\n",
    "      select \n",
    "      XO.x1 as [Date]\n",
    "\t  ,XO.x8 as [Model]\n",
    "      ,XO.x13 as Line\n",
    "      ,XO.x12 as [Machine]\n",
    "      ,XO.x2 as [%Yield]\n",
    "      ,XO.x3 as [Cycle_time (sec)]\n",
    "      ,XO.x4 as [Down time (min)]\n",
    "      ,XO.x5 as [AVG]\n",
    "      ,XO.x6 as [STD]\n",
    "      ,XO.x7 as [CPK]\n",
    "    \n",
    "      ,x11 as [USL]\n",
    "      ,x10 as [CL]\n",
    "      ,x9 as [LSL]\n",
    "\t  ,@Parameter as Parameter\n",
    "      from XO\n",
    "        \"\"\"\n",
    "dataSTD = pd.read_sql(query, cnxn)\n",
    "print(dataSTD.head(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT\\AppData\\Local\\Temp\\ipykernel_17720\\4262995815.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  datasets = pd.read_sql(query, cnxn)\n"
     ]
    }
   ],
   "source": [
    "# Your existing code here...\n",
    "\n",
    "# Execute the SQL query and store the results in the 'datasets' DataFrame\n",
    "datasets = pd.read_sql(query, cnxn)\n",
    "\n",
    "# Your existing code here...\n",
    "\n",
    "# Establish a new connection for inserting the data into the target table\n",
    "insert_server = '192.168.101.219'\n",
    "insert_database = 'DataforAnalysis'\n",
    "insert_username = 'DATALYZER'\n",
    "insert_password = 'NMB54321'\n",
    "insert_cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+insert_server+';DATABASE='+insert_database+';UID='+insert_username+';PWD='+ insert_password)\n",
    "insert_cursor = insert_cnxn.cursor()\n",
    "\n",
    "# Iterate through the rows of the 'datasets' DataFrame and insert data into the target table\n",
    "for index, row in dataSTD.iterrows():\n",
    "    insert_query = f\"\"\"\n",
    "        insert into [DataforAnalysis].[dbo].[SPC_STD_MC] ([Date], [Model], [Line], [Machine], [%Yield], [Cycle_time (sec)],\n",
    "        [Down time (min)], [AVG], [STD], [CPK],[LSL],[CL],[USL],[Parameter])\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? , ? )\n",
    "    \"\"\"\n",
    "    values = (row['Date'], row['Model'], row['Line'], row['Machine'], row['%Yield'], row['Cycle_time (sec)'],\n",
    "              row['Down time (min)'], row['AVG'], row['STD'], row['CPK'],row['LSL'],row['CL'],row['USL'], row['Parameter'])\n",
    "    insert_cursor.execute(insert_query, values)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "insert_cursor.commit()\n",
    "insert_cursor.close()\n",
    "insert_cnxn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
